{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to check the images in our dataset for their sizes and number of color components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Import necessary libs\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "      <th>Components</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>350.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>350.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>350.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>350.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>350.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Width  Height  Components\n",
       "0  350.0   350.0         3.0\n",
       "1  350.0   350.0         3.0\n",
       "2  350.0   350.0         3.0\n",
       "3  350.0   350.0         3.0\n",
       "4  350.0   350.0         3.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Check image size and color components\"\"\"\n",
    "df = pd.DataFrame()\n",
    "\n",
    "targetdir = \"images\"\n",
    "filelist = glob.glob(targetdir+str(\"/*\"))\n",
    "for file in filelist:\n",
    "    img = cv.imread(file)\n",
    "    img_shape = img.shape\n",
    "    #print(img_shape)\n",
    "    df = df.append(pd.Series(img_shape),ignore_index=True)\n",
    "df = df.rename(columns={0: \"Width\", 1: \"Height\", 2:\"Components\"})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we need to determine the minimum & maximum width and height from all the image sizes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13718 entries, 0 to 13717\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Width       13718 non-null  float64\n",
      " 1   Height      13718 non-null  float64\n",
      " 2   Components  13718 non-null  float64\n",
      "dtypes: float64(3)\n",
      "memory usage: 321.6 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "      <th>Components</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>536.000000</td>\n",
       "      <td>441.000000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>335.768698</td>\n",
       "      <td>333.548039</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>58.700772</td>\n",
       "      <td>63.898948</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Width      Height  Components\n",
       "max   536.000000  441.000000         3.0\n",
       "min    24.000000   18.000000         3.0\n",
       "mean  335.768698  333.548039         3.0\n",
       "std    58.700772   63.898948         0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =df.rename(columns={\"Rows\": \"Width\", \"Columns\": \"Height\", 2:\"Components\"})\n",
    "df.agg(['max', 'min', 'mean', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13690 entries, 0 to 13689\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   user.id  13690 non-null  object\n",
      " 1   image    13690 non-null  object\n",
      " 2   emotion  13690 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 321.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load in image data\n",
    "image_info = pd.read_csv('data/legend.csv',delimiter=',')\n",
    "image_info.head()\n",
    "image_info.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user.id</th>\n",
       "      <th>image</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>628</td>\n",
       "      <td>facial-expressions_2868588k.jpg</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>628</td>\n",
       "      <td>facial-expressions_2868585k.jpg</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>628</td>\n",
       "      <td>facial-expressions_2868584k.jpg</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>628</td>\n",
       "      <td>facial-expressions_2868582k.jpg</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dwdii</td>\n",
       "      <td>Aaron_Eckhart_0001.jpg</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user.id                            image   emotion\n",
       "0     628  facial-expressions_2868588k.jpg     anger\n",
       "1     628  facial-expressions_2868585k.jpg  surprise\n",
       "2     628  facial-expressions_2868584k.jpg   disgust\n",
       "3     628  facial-expressions_2868582k.jpg      fear\n",
       "4   dwdii           Aaron_Eckhart_0001.jpg   neutral"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anger', 'surprise', 'disgust', 'fear', 'neutral', 'happiness',\n",
       "       'sadness', 'contempt', 'NEUTRAL', 'SADNESS', 'DISGUST', 'FEAR',\n",
       "       'SURPRISE', 'ANGER', 'HAPPINESS'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_info[\"emotion\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral      6717\n",
       "happiness    5309\n",
       "HAPPINESS     387\n",
       "surprise      356\n",
       "anger         228\n",
       "DISGUST       195\n",
       "NEUTRAL       151\n",
       "SADNESS       144\n",
       "sadness       124\n",
       "ANGER          24\n",
       "fear           13\n",
       "disgust        13\n",
       "SURPRISE       12\n",
       "contempt        9\n",
       "FEAR            8\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_info[\"emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral      6868\n",
       "happiness    5696\n",
       "surprise      368\n",
       "sadness       268\n",
       "anger         252\n",
       "disgust       208\n",
       "fear           21\n",
       "contempt        9\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the emotion string to lowercase\n",
    "image_info[\"emotion\"] = image_info[\"emotion\"].str.lower()\n",
    "image_info[\"emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be easily noticable that the emotion categories are not equally distributed here. Hence we need to drop some images from neutral and happiness category to make the distribution even for all categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Merge the contempt into disgust category\"\"\"\n",
    "image_info[\"emotion\"] = image_info[\"emotion\"].replace(\"contempt\",\"disgust\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral      6868\n",
       "happiness    5696\n",
       "surprise      368\n",
       "sadness       268\n",
       "anger         252\n",
       "disgust       217\n",
       "fear           21\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_info[\"emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle the dataset , iterate over it and select 500 images from neutral and happiness category\n",
    "image_info = image_info.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if shuffle is performed again remove already selected images and perform the partition using below cell again\n",
    "#!rm -f selectedImages/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#move above selected images into a separate dataset folder\n",
    "neutral = 0\n",
    "happy = 0\n",
    "selectedImages = pd.DataFrame(columns=[\"image\",\"emotion\"])\n",
    "for index, row in image_info.iterrows():\n",
    "    #if happy >= 500 and neutral >=500:\n",
    "     #   break\n",
    "    if row[\"emotion\"] == \"happiness\":\n",
    "        happy += 1\n",
    "        if happy > 500:\n",
    "            continue\n",
    "    elif row[\"emotion\"] == \"neutral\":\n",
    "        neutral += 1\n",
    "        if neutral > 500:\n",
    "            continue\n",
    "    selectedImages = selectedImages.append(pd.Series(row),ignore_index=True)\n",
    "    #print(row)\n",
    "    \n",
    "    ##uncomment if need to copy the images to another folder\n",
    "    \n",
    "    #cmdstring = \"cp images/{} selectedImages/.\".format(row[\"image\"])\n",
    "    #os.system(cmdstring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral      500\n",
       "happiness    500\n",
       "surprise     368\n",
       "sadness      268\n",
       "anger        252\n",
       "disgust      217\n",
       "fear          21\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "selectedImages[\"emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2126\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l selectedImages/ | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "selectedImages = selectedImages.drop(['user.id'], axis=1) #we donot need user.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2126 entries, 0 to 2125\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   image    2126 non-null   object\n",
      " 1   emotion  2126 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 33.3+ KB\n"
     ]
    }
   ],
   "source": [
    "selectedImages.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide this dataset into test train and validation set\n",
    "train, validate, test = np.split(selectedImages.sample(frac=1), [int(.6*len(selectedImages)), int(.8*len(selectedImages))])\n",
    "\n",
    "#https://datascience.stackexchange.com/questions/15135/train-test-validation-set-splitting-in-sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1275 entries, 41 to 1714\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   image    1275 non-null   object\n",
      " 1   emotion  1275 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 29.9+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 426 entries, 514 to 474\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   image    426 non-null    object\n",
      " 1   emotion  426 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 10.0+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 425 entries, 492 to 1955\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   image    425 non-null    object\n",
      " 1   emotion  425 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 10.0+ KB\n"
     ]
    }
   ],
   "source": [
    "validate.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral      305\n",
       "happiness    294\n",
       "surprise     217\n",
       "sadness      163\n",
       "anger        155\n",
       "disgust      127\n",
       "fear          14\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "happiness    107\n",
       "neutral      104\n",
       "surprise      68\n",
       "sadness       53\n",
       "disgust       47\n",
       "anger         45\n",
       "fear           1\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate[\"emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "happiness    99\n",
       "neutral      91\n",
       "surprise     83\n",
       "anger        52\n",
       "sadness      52\n",
       "disgust      43\n",
       "fear          6\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    305\n",
       "0    294\n",
       "2    217\n",
       "4    163\n",
       "3    155\n",
       "5    127\n",
       "6     14\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def categorical2Numerical(df):\n",
    "    category = {'happiness': 0, 'neutral': 1, 'surprise':2, 'anger':3, 'sadness': 4, 'disgust':5, 'fear':6}\n",
    "    df.emotion = [category[item] for item in df.emotion]\n",
    "    return df\n",
    "train[\"emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving category mapping so when we need to reverse map the value to it's original emotion \n",
    "import json\n",
    "\n",
    "with open('category.json', 'w') as fp:\n",
    "    json.dump(category, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "validate = categorical2Numerical(validate)\n",
    "test = categorical2Numerical(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    107\n",
       "1    104\n",
       "2     68\n",
       "4     53\n",
       "5     47\n",
       "3     45\n",
       "6      1\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate[\"emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    99\n",
       "1    91\n",
       "2    83\n",
       "4    52\n",
       "3    52\n",
       "5    43\n",
       "6     6\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dropColumn(df,i):\n",
    "    df = df.drop(df.columns[i], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1912</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      emotion\n",
       "41          1\n",
       "381         1\n",
       "107         0\n",
       "1172        4\n",
       "1912        2"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train= dropColumn(train,0)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above the distribution looks justified for each category of emotions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to save this selected images data frame into a csv files so that we can load them again as they are.\n",
    "selectedImages.to_csv('selectedImages.csv')\n",
    "train.to_csv('train.csv')\n",
    "validate.to_csv('validate.csv')\n",
    "test.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moveImageToFolder(df, folder):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    for index, row in df.iterrows():\n",
    "        cmdstring = \"mv selectedImages/{} {}/.\".format(row[\"image\"],folder)\n",
    "        os.system(cmdstring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "moveImageToFolder(train,\"selectedImages/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "moveImageToFolder(validate,\"selectedImages/valid\")\n",
    "moveImageToFolder(test,\"selectedImages/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCategoryFolder(df, folder):\n",
    "    category = {0:'happiness', 1:'neutral', 2:'surprise', 3:'anger', 4:'sadness', 5:'disgust', 6:'fear'}\n",
    "    for index, row in df.iterrows():\n",
    "        \n",
    "        currentPath = os.path.join(folder,category[row[\"emotion\"]])\n",
    "        if not os.path.exists(currentPath):\n",
    "            os.makedirs(currentPath)\n",
    "        cmdstring = \"mv {}/{} {}/.\".format(folder,row[\"image\"],currentPath)\n",
    "        print(cmdstring)\n",
    "        os.system(cmdstring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('selectedImages/train.csv',delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createCategoryFolder(train,\"selectedImages/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createCategoryFolder(test,\"selectedImages/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createCategoryFolder(validate,\"selectedImages/valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session and role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# create an S3 bucket\n",
    "bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# should be the name of directory you created to save your features data\n",
    "data_dir = 'selectedImages'\n",
    "\n",
    "# set prefix, a descriptive name for a directory  \n",
    "prefix = 'emotion-detection'\n",
    "\n",
    "# upload all data to S3\n",
    "#input_data = sagemaker_session.upload_data(path=data_dir, bucket=bucket, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion-detection/output/sagemaker-pytorch-2020-12-04-17-51-14-952/debug-output/training_job_end.ts\n",
      "1\n",
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "# confirm that data is in S3 bucket\n",
    "\n",
    "empty_check = []\n",
    "for obj in boto3.resource('s3').Bucket(bucket).objects.all():\n",
    "    empty_check.append(obj.key)\n",
    "    print(obj.key)\n",
    "    break\n",
    "print(len(empty_check))\n",
    "assert len(empty_check) !=0, 'S3 bucket is empty.'\n",
    "print('Test passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = './' + data_dir + '/train'\n",
    "valid_dir = data_dir + '/valid'\n",
    "test_dir = data_dir + '/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Read in only the first 250 rows\n",
    "train_sample = pd.read_csv(os.path.join(data_dir, 'train.csv'), names=None, nrows=50)\n",
    "\n",
    "# Turn the input pandas dataframe into tensors\n",
    "#print(train_sample.head())\n",
    "#train_sample_y = torch.from_numpy(train_sample['emotion'].values)\n",
    "train_transforms = transforms.Compose([transforms.Grayscale(1),\n",
    "                                       transforms.RandomRotation(30, fill=(0,)),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.Resize((224,224)),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize((0.5, ), (0.5, ))])\n",
    "valid_transforms = transforms.Compose([transforms.Grayscale(1),\n",
    "                                       transforms.Resize((224,224)),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize((0.5, ), (0.5, ))])\n",
    "test_transforms = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                             std=[0.229, 0.224, 0.225])])\n",
    "# Build the dataset\n",
    "\n",
    "train_data = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "valid_data = datasets.ImageFolder(valid_dir, transform=valid_transforms)\n",
    "test_data = datasets.ImageFolder(test_dir, transform=test_transforms)\n",
    "# TODO: Using the image datasets and the trainforms, define the dataloaders\n",
    "\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=10, shuffle=True)\n",
    "validloader = torch.utils.data.DataLoader(valid_data, batch_size=10, shuffle=False)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pygmentize model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pygmentize train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "\n",
    "class EmotionClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    This is the simple CNN model we will be using to perform emotion classification for seven emotions\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the model by settingg up the various layers.\n",
    "        \"\"\"\n",
    "        super(EmotionClassifier, self).__init__()\n",
    "        \n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            # Defining a 2D convolution layer\n",
    "            Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            ReLU(inplace=True),\n",
    "            # adding batch normalization\n",
    "            BatchNorm2d(32),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            # adding dropout\n",
    "            Dropout(p=0.25),\n",
    "            # Defining another 2D convolution layer\n",
    "            Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            ReLU(inplace=True),\n",
    "            # adding batch normalization\n",
    "            BatchNorm2d(64),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            # adding dropout\n",
    "            Dropout(p=0.25),\n",
    "            # Defining another 2D convolution layer\n",
    "            Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            ReLU(inplace=True),\n",
    "            # adding batch normalization\n",
    "            BatchNorm2d(128),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            # adding dropout\n",
    "            Dropout(p=0.25),\n",
    "            # Defining another 2D convolution layer\n",
    "            Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            ReLU(inplace=True),\n",
    "            # adding batch normalization\n",
    "            BatchNorm2d(128),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            # adding dropout\n",
    "            Dropout(p=0.25),\n",
    "        )\n",
    "\n",
    "        self.linear_layers = nn.Sequential(\n",
    "            Linear(128 * 14 * 14, 512),\n",
    "            ReLU(inplace=True),\n",
    "            Dropout(),\n",
    "            Linear(512, 256),\n",
    "            ReLU(inplace=True),\n",
    "            Dropout(),\n",
    "            Linear(256,84),\n",
    "            ReLU(inplace=True),\n",
    "            Dropout(),\n",
    "            Linear(84,7)\n",
    "        )\n",
    "\n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear_layers(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, epochs, optimizer, loss_fn, device):\n",
    "    prev_acc = 0\n",
    "    accuracy = 0\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:         \n",
    "        #for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            batch_X, batch_y = batch\n",
    "            \n",
    "            batch_X = batch_X.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            \n",
    "            # TODO: Complete this train method to train the model provided.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            logps = model.forward(batch_X)\n",
    "            m = nn.LogSoftmax(dim=1)\n",
    "            #nll_loss = nn.NLLLoss()\n",
    "            #output = nll_loss(m(input), target)\n",
    "            loss = loss_fn(m(logps), batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.data.item()\n",
    "        print(\"Epoch: {}, NLLLoss: {}\".format(epoch, total_loss / len(train_loader)))\n",
    "        model.eval()\n",
    "        valid_loss = 0\n",
    "        #accuracy = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in validloader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                logps = model.forward(inputs)\n",
    "                m = nn.LogSoftmax(dim=1)\n",
    "                batch_loss = loss_fn(m(logps), labels)\n",
    "\n",
    "                valid_loss += batch_loss.item()\n",
    "\n",
    "                # Calculate accuracy\n",
    "                ps = torch.exp(logps)\n",
    "                top_p, top_class = ps.topk(1, dim=1)\n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "                valid_acc = accuracy/len(validloader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "      f\"Train loss: {total_loss / len(train_loader):.3f}.. \"\n",
    "      f\"Valid loss: {valid_loss/len(validloader):.3f}.. \"\n",
    "      f\"Validation accuracy: {valid_acc:.3f}\")\n",
    "        \n",
    "        model.train()\n",
    "        if valid_acc-prev_acc < .1 and valid_acc > .9:\n",
    "            break\n",
    "        else:\n",
    "            prev_acc = valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "#import EmotionClassifier as E\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#model = EmotionClassifier().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.002)\n",
    "loss_fn = torch.nn.NLLLoss() #torch.nn.BCELoss()\n",
    "\n",
    "#train(model, trainloader, 2, optimizer, loss_fn, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sagemaker-containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(entry_point=\"train.py\",\n",
    "                    source_dir=\"./\",\n",
    "                    role=role,\n",
    "                    framework_version='1.0.0',\n",
    "                    py_version='py3',\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type='ml.p2.xlarge',\n",
    "                    output_path='s3://{}/{}/modelOutput'.format(sagemaker_session.default_bucket(), prefix),\n",
    "                    hyperparameters={\n",
    "                        'epochs': 200,\n",
    "                        'learning_rate': 0.002\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path='s3://{}/{}'.format(sagemaker_session.default_bucket(), prefix)\n",
    "#estimator.fit({'train':s3://my-bucket/training_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-2-769207522942/emotion-detection\n"
     ]
    }
   ],
   "source": [
    "print(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload_data : s3://sagemaker-us-east-2-769207522942/emotion-detection/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "upload_data = sagemaker_session.upload_data(path='./requirements.txt', bucket=bucket, key_prefix=prefix)\n",
    "\n",
    "print('upload_data : {}'.format(upload_data))\n",
    "#sagemaker_session.upload_data(path=data_dir, bucket=bucket, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-15 16:15:32 Starting - Starting the training job...\n",
      "2020-12-15 16:15:56 Starting - Launching requested ML instancesProfilerReport-1608048905: InProgress\n",
      "......\n",
      "2020-12-15 16:16:57 Starting - Preparing the instances for training.........\n",
      "2020-12-15 16:18:28 Downloading - Downloading input data.........\n",
      "2020-12-15 16:20:01 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-12-15 16:20:03,272 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-12-15 16:20:03,301 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-12-15 16:20:03,302 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-12-15 16:20:15,205 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-12-15 16:20:15,206 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-12-15 16:20:15,206 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-12-15 16:20:15,206 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install -U . -r requirements.txt\u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mCollecting sagemaker-containers (from -r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/f3/4d/ee2ef5a6cccdcf39aa1b3c8f978a462f0c32faddab807a8ba3506b898262/sagemaker_containers-2.8.6.post2.tar.gz (51kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from sagemaker-containers->-r requirements.txt (line 1)) (1.16.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: boto3 in /usr/local/lib/python3.6/dist-packages (from sagemaker-containers->-r requirements.txt (line 1)) (1.9.158)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from sagemaker-containers->-r requirements.txt (line 1)) (1.12.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: pip in /usr/local/lib/python3.6/dist-packages (from sagemaker-containers->-r requirements.txt (line 1)) (18.1)\u001b[0m\n",
      "\u001b[34mCollecting flask==1.1.1 (from sagemaker-containers->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/9b/93/628509b8d5dc749656a9641f4caf13540e2cdec85276964ff8f43bbb1d3b/Flask-1.1.1-py2.py3-none-any.whl (94kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: gunicorn in /usr/local/lib/python3.6/dist-packages (from sagemaker-containers->-r requirements.txt (line 1)) (19.9.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: typing in /usr/local/lib/python3.6/dist-packages (from sagemaker-containers->-r requirements.txt (line 1)) (3.6.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from sagemaker-containers->-r requirements.txt (line 1)) (1.3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: gevent in /usr/local/lib/python3.6/dist-packages (from sagemaker-containers->-r requirements.txt (line 1)) (1.4.0)\u001b[0m\n",
      "\u001b[34mCollecting inotify_simple==1.2.1 (from sagemaker-containers->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/7b/2d/c7450cc2c6ec9be3a6f35d7d22f6866f156a32f4ea97e75b13b27ad300fd/inotify_simple-1.2.1.tar.gz\u001b[0m\n",
      "\u001b[34mCollecting werkzeug>=0.15.5 (from sagemaker-containers->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/cc/94/5f7079a0e00bd6863ef8f1da638721e9da21e5bacee597595b318f71d62e/Werkzeug-1.0.1-py2.py3-none-any.whl (298kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: paramiko>=2.4.2 in /usr/local/lib/python3.6/dist-packages (from sagemaker-containers->-r requirements.txt (line 1)) (2.4.2)\u001b[0m\n",
      "\u001b[34mCollecting psutil>=5.6.7 (from sagemaker-containers->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/33/e0/82d459af36bda999f82c7ea86c67610591cf5556168f48fd6509e5fa154d/psutil-5.7.3.tar.gz (465kB)\u001b[0m\n",
      "\u001b[34mCollecting protobuf>=3.1 (from sagemaker-containers->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34m  Downloading https://files.pythonhosted.org/packages/fe/fd/247ef25f5ec5f9acecfbc98ca3c6aaf66716cf52509aca9a93583d410493/protobuf-3.14.0-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: scipy>=1.2.2 in /usr/local/lib/python3.6/dist-packages (from sagemaker-containers->-r requirements.txt (line 1)) (1.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: botocore<1.13.0,>=1.12.158 in /usr/local/lib/python3.6/dist-packages (from boto3->sagemaker-containers->-r requirements.txt (line 1)) (1.12.158)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->sagemaker-containers->-r requirements.txt (line 1)) (0.9.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->sagemaker-containers->-r requirements.txt (line 1)) (0.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from flask==1.1.1->sagemaker-containers->-r requirements.txt (line 1)) (2.10.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask==1.1.1->sagemaker-containers->-r requirements.txt (line 1)) (1.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask==1.1.1->sagemaker-containers->-r requirements.txt (line 1)) (7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: greenlet>=0.4.14; platform_python_implementation == \"CPython\" in /usr/local/lib/python3.6/dist-packages (from gevent->sagemaker-containers->-r requirements.txt (line 1)) (0.4.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: bcrypt>=3.1.3 in /usr/local/lib/python3.6/dist-packages (from paramiko>=2.4.2->sagemaker-containers->-r requirements.txt (line 1)) (3.1.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from paramiko>=2.4.2->sagemaker-containers->-r requirements.txt (line 1)) (0.4.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: pynacl>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from paramiko>=2.4.2->sagemaker-containers->-r requirements.txt (line 1)) (1.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: cryptography>=1.5 in /usr/local/lib/python3.6/dist-packages (from paramiko>=2.4.2->sagemaker-containers->-r requirements.txt (line 1)) (2.6.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.158->boto3->sagemaker-containers->-r requirements.txt (line 1)) (2.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.158->boto3->sagemaker-containers->-r requirements.txt (line 1)) (0.14)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: urllib3<1.26,>=1.20; python_version >= \"3.4\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.158->boto3->sagemaker-containers->-r requirements.txt (line 1)) (1.25.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->flask==1.1.1->sagemaker-containers->-r requirements.txt (line 1)) (1.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: cffi>=1.1 in /usr/local/lib/python3.6/dist-packages (from bcrypt>=3.1.3->paramiko>=2.4.2->sagemaker-containers->-r requirements.txt (line 1)) (1.12.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: asn1crypto>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from cryptography>=1.5->paramiko>=2.4.2->sagemaker-containers->-r requirements.txt (line 1)) (0.24.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko>=2.4.2->sagemaker-containers->-r requirements.txt (line 1)) (2.19)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: sagemaker-containers, train, inotify-simple, psutil\n",
      "  Running setup.py bdist_wheel for sagemaker-containers: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for sagemaker-containers: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/7e/8f/2d/8d3d759b6ec3a3be6f838856cc3c734412868a7ea16c57043f\n",
      "  Running setup.py bdist_wheel for train: started\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-vceiy6wl/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for inotify-simple: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for inotify-simple: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/28/77/f9/52cc89b27110b3fe0df40290275bd1151db9d0c7b15733cc3b\n",
      "  Running setup.py bdist_wheel for psutil: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for psutil: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/42/32/da/8b12fd6b138c733efd03cfde6c6c8191a32842f9e82aa45fbf\u001b[0m\n",
      "\u001b[34mSuccessfully built sagemaker-containers train inotify-simple psutil\u001b[0m\n",
      "\u001b[34mInstalling collected packages: werkzeug, flask, inotify-simple, psutil, protobuf, sagemaker-containers, train\n",
      "  Found existing installation: Werkzeug 0.15.4\n",
      "    Uninstalling Werkzeug-0.15.4:\n",
      "      Successfully uninstalled Werkzeug-0.15.4\n",
      "  Found existing installation: Flask 1.0.3\n",
      "    Uninstalling Flask-1.0.3:\n",
      "      Successfully uninstalled Flask-1.0.3\n",
      "  Found existing installation: inotify-simple 1.1.8\n",
      "    Uninstalling inotify-simple-1.1.8:\n",
      "      Successfully uninstalled inotify-simple-1.1.8\u001b[0m\n",
      "\u001b[34m  Found existing installation: psutil 5.4.8\n",
      "    Uninstalling psutil-5.4.8:\n",
      "      Successfully uninstalled psutil-5.4.8\n",
      "  Found existing installation: sagemaker-containers 2.4.10.post0\n",
      "    Uninstalling sagemaker-containers-2.4.10.post0:\n",
      "      Successfully uninstalled sagemaker-containers-2.4.10.post0\u001b[0m\n",
      "\u001b[34mSuccessfully installed flask-1.1.1 inotify-simple-1.2.1 protobuf-3.14.0 psutil-5.7.3 sagemaker-containers-2.8.6.post2 train-1.0.0 werkzeug-1.0.1\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 20.3.3 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-12-15 16:21:26,150 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 200,\n",
      "        \"learning_rate\": 0.002\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-pytorch-2020-12-15-16-15-05-577\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-769207522942/sagemaker-pytorch-2020-12-15-16-15-05-577/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":200,\"learning_rate\":0.002}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-769207522942/sagemaker-pytorch-2020-12-15-16-15-05-577/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":200,\"learning_rate\":0.002},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-pytorch-2020-12-15-16-15-05-577\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-769207522942/sagemaker-pytorch-2020-12-15-16-15-05-577/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"200\",\"--learning_rate\",\"0.002\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=200\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.002\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m train --epochs 200 --learning_rate 0.002\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cuda.\u001b[0m\n",
      "\u001b[34mGet train and valid data loader.\u001b[0m\n",
      "\u001b[34mEpoch: 1, NLLLoss: 1.825979232788086\u001b[0m\n",
      "\u001b[34mEpoch 2/200.. Train loss: 1.826.. Valid loss: 1.621.. Validation accuracy: 0.273\u001b[0m\n",
      "\u001b[34mEpoch: 2, NLLLoss: 1.665232138974326\u001b[0m\n",
      "\u001b[34mEpoch 3/200.. Train loss: 1.665.. Valid loss: 1.564.. Validation accuracy: 0.281\u001b[0m\n",
      "\u001b[34mEpoch: 3, NLLLoss: 1.605484391961779\u001b[0m\n",
      "\u001b[34mEpoch 4/200.. Train loss: 1.605.. Valid loss: 1.647.. Validation accuracy: 0.283\u001b[0m\n",
      "\u001b[34mEpoch: 4, NLLLoss: 1.5877931032861983\u001b[0m\n",
      "\u001b[34mEpoch 5/200.. Train loss: 1.588.. Valid loss: 1.690.. Validation accuracy: 0.288\u001b[0m\n",
      "\u001b[34mEpoch: 5, NLLLoss: 1.5776979412351335\u001b[0m\n",
      "\u001b[34mEpoch 6/200.. Train loss: 1.578.. Valid loss: 1.750.. Validation accuracy: 0.210\u001b[0m\n",
      "\u001b[34mEpoch: 6, NLLLoss: 1.600296676158905\u001b[0m\n",
      "\u001b[34mEpoch 7/200.. Train loss: 1.600.. Valid loss: 1.663.. Validation accuracy: 0.257\u001b[0m\n",
      "\u001b[34mEpoch: 7, NLLLoss: 1.595048257282802\u001b[0m\n",
      "\u001b[34mEpoch 8/200.. Train loss: 1.595.. Valid loss: 1.624.. Validation accuracy: 0.304\u001b[0m\n",
      "\u001b[34mEpoch: 8, NLLLoss: 1.5892419559614999\u001b[0m\n",
      "\u001b[34mEpoch 9/200.. Train loss: 1.589.. Valid loss: 1.597.. Validation accuracy: 0.352\u001b[0m\n",
      "\u001b[34mEpoch: 9, NLLLoss: 1.5918997781617301\u001b[0m\n",
      "\u001b[34mEpoch 10/200.. Train loss: 1.592.. Valid loss: 1.610.. Validation accuracy: 0.270\u001b[0m\n",
      "\u001b[34mEpoch: 10, NLLLoss: 1.566393256187439\u001b[0m\n",
      "\u001b[34mEpoch 11/200.. Train loss: 1.566.. Valid loss: 1.481.. Validation accuracy: 0.358\u001b[0m\n",
      "\u001b[34mEpoch: 11, NLLLoss: 1.5614749959536962\u001b[0m\n",
      "\u001b[34mEpoch 12/200.. Train loss: 1.561.. Valid loss: 1.615.. Validation accuracy: 0.327\u001b[0m\n",
      "\u001b[34mEpoch: 12, NLLLoss: 1.5569936718259538\u001b[0m\n",
      "\u001b[34mEpoch 13/200.. Train loss: 1.557.. Valid loss: 1.768.. Validation accuracy: 0.238\u001b[0m\n",
      "\u001b[34mEpoch: 13, NLLLoss: 1.5359999196869987\u001b[0m\n",
      "\u001b[34mEpoch 14/200.. Train loss: 1.536.. Valid loss: 1.586.. Validation accuracy: 0.330\u001b[0m\n",
      "\u001b[34mEpoch: 14, NLLLoss: 1.557225797857557\u001b[0m\n",
      "\u001b[34mEpoch 15/200.. Train loss: 1.557.. Valid loss: 1.533.. Validation accuracy: 0.352\u001b[0m\n",
      "\u001b[34mEpoch: 15, NLLLoss: 1.5327596749578203\u001b[0m\n",
      "\u001b[34mEpoch 16/200.. Train loss: 1.533.. Valid loss: 1.554.. Validation accuracy: 0.286\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mEpoch: 16, NLLLoss: 1.518724194594792\u001b[0m\n",
      "\u001b[34mEpoch 17/200.. Train loss: 1.519.. Valid loss: 1.488.. Validation accuracy: 0.334\u001b[0m\n",
      "\u001b[34mEpoch: 17, NLLLoss: 1.5183024576732091\u001b[0m\n",
      "\u001b[34mEpoch 18/200.. Train loss: 1.518.. Valid loss: 1.471.. Validation accuracy: 0.362\u001b[0m\n",
      "\u001b[34mEpoch: 18, NLLLoss: 1.5628426330430167\u001b[0m\n",
      "\u001b[34mEpoch 19/200.. Train loss: 1.563.. Valid loss: 1.631.. Validation accuracy: 0.281\u001b[0m\n",
      "\u001b[34mEpoch: 19, NLLLoss: 1.5716211880956377\u001b[0m\n",
      "\u001b[34mEpoch 20/200.. Train loss: 1.572.. Valid loss: 1.504.. Validation accuracy: 0.332\u001b[0m\n",
      "\u001b[34mEpoch: 20, NLLLoss: 1.5208437613078527\u001b[0m\n",
      "\u001b[34mEpoch 21/200.. Train loss: 1.521.. Valid loss: 1.565.. Validation accuracy: 0.330\u001b[0m\n",
      "\u001b[34mEpoch: 21, NLLLoss: 1.524686370577131\u001b[0m\n",
      "\u001b[34mEpoch 22/200.. Train loss: 1.525.. Valid loss: 1.485.. Validation accuracy: 0.308\u001b[0m\n",
      "\u001b[34mEpoch: 22, NLLLoss: 1.534466300691877\u001b[0m\n",
      "\u001b[34mEpoch 23/200.. Train loss: 1.534.. Valid loss: 1.464.. Validation accuracy: 0.389\u001b[0m\n",
      "\u001b[34mEpoch: 23, NLLLoss: 1.5259496825081962\u001b[0m\n",
      "\u001b[34mEpoch 24/200.. Train loss: 1.526.. Valid loss: 1.538.. Validation accuracy: 0.329\u001b[0m\n",
      "\u001b[34mEpoch: 24, NLLLoss: 1.5049307176045008\u001b[0m\n",
      "\u001b[34mEpoch 25/200.. Train loss: 1.505.. Valid loss: 1.454.. Validation accuracy: 0.366\u001b[0m\n",
      "\u001b[34mEpoch: 25, NLLLoss: 1.4714727061135429\u001b[0m\n",
      "\u001b[34mEpoch 26/200.. Train loss: 1.471.. Valid loss: 1.505.. Validation accuracy: 0.352\u001b[0m\n",
      "\u001b[34mEpoch: 26, NLLLoss: 1.4918999246188573\u001b[0m\n",
      "\u001b[34mEpoch 27/200.. Train loss: 1.492.. Valid loss: 1.643.. Validation accuracy: 0.336\u001b[0m\n",
      "\u001b[34mEpoch: 27, NLLLoss: 1.5362027032034737\u001b[0m\n",
      "\u001b[34mEpoch 28/200.. Train loss: 1.536.. Valid loss: 1.567.. Validation accuracy: 0.339\u001b[0m\n",
      "\u001b[34mEpoch: 28, NLLLoss: 1.5560167346681868\u001b[0m\n",
      "\u001b[34mEpoch 29/200.. Train loss: 1.556.. Valid loss: 1.479.. Validation accuracy: 0.330\u001b[0m\n",
      "\u001b[34mEpoch: 29, NLLLoss: 1.514027714729309\u001b[0m\n",
      "\u001b[34mEpoch 30/200.. Train loss: 1.514.. Valid loss: 1.508.. Validation accuracy: 0.365\u001b[0m\n",
      "\u001b[34mEpoch: 30, NLLLoss: 1.5267856291362218\u001b[0m\n",
      "\u001b[34mEpoch 31/200.. Train loss: 1.527.. Valid loss: 1.488.. Validation accuracy: 0.366\u001b[0m\n",
      "\u001b[34mEpoch: 31, NLLLoss: 1.4968393274715968\u001b[0m\n",
      "\u001b[34mEpoch 32/200.. Train loss: 1.497.. Valid loss: 1.432.. Validation accuracy: 0.387\u001b[0m\n",
      "\u001b[34mEpoch: 32, NLLLoss: 1.481511456625802\u001b[0m\n",
      "\u001b[34mEpoch 33/200.. Train loss: 1.482.. Valid loss: 1.514.. Validation accuracy: 0.372\u001b[0m\n",
      "\u001b[34mEpoch: 33, NLLLoss: 1.4928777047566004\u001b[0m\n",
      "\u001b[34mEpoch 34/200.. Train loss: 1.493.. Valid loss: 1.412.. Validation accuracy: 0.383\u001b[0m\n",
      "\u001b[34mEpoch: 34, NLLLoss: 1.5092734779630388\u001b[0m\n",
      "\u001b[34mEpoch 35/200.. Train loss: 1.509.. Valid loss: 1.575.. Validation accuracy: 0.345\u001b[0m\n",
      "\u001b[34mEpoch: 35, NLLLoss: 1.5273019075393677\u001b[0m\n",
      "\u001b[34mEpoch 36/200.. Train loss: 1.527.. Valid loss: 1.486.. Validation accuracy: 0.348\u001b[0m\n",
      "\u001b[34mEpoch: 36, NLLLoss: 1.4977630461965288\u001b[0m\n",
      "\u001b[34mEpoch 37/200.. Train loss: 1.498.. Valid loss: 1.448.. Validation accuracy: 0.406\u001b[0m\n",
      "\u001b[34mEpoch: 37, NLLLoss: 1.4578744513647897\u001b[0m\n",
      "\u001b[34mEpoch 38/200.. Train loss: 1.458.. Valid loss: 1.558.. Validation accuracy: 0.345\u001b[0m\n",
      "\u001b[34mEpoch: 38, NLLLoss: 1.4702439904212952\u001b[0m\n",
      "\u001b[34mEpoch 39/200.. Train loss: 1.470.. Valid loss: 1.476.. Validation accuracy: 0.385\u001b[0m\n",
      "\u001b[34mEpoch: 39, NLLLoss: 1.4834776265280587\u001b[0m\n",
      "\u001b[34mEpoch 40/200.. Train loss: 1.483.. Valid loss: 1.454.. Validation accuracy: 0.382\u001b[0m\n",
      "\u001b[34mEpoch: 40, NLLLoss: 1.482254479612623\u001b[0m\n",
      "\u001b[34mEpoch 41/200.. Train loss: 1.482.. Valid loss: 1.465.. Validation accuracy: 0.409\u001b[0m\n",
      "\u001b[34mEpoch: 41, NLLLoss: 1.4585385833467757\u001b[0m\n",
      "\u001b[34mEpoch 42/200.. Train loss: 1.459.. Valid loss: 1.453.. Validation accuracy: 0.420\u001b[0m\n",
      "\u001b[34mEpoch: 42, NLLLoss: 1.4771817837442671\u001b[0m\n",
      "\u001b[34mEpoch 43/200.. Train loss: 1.477.. Valid loss: 1.482.. Validation accuracy: 0.439\u001b[0m\n",
      "\u001b[34mEpoch: 43, NLLLoss: 1.4627094779695784\u001b[0m\n",
      "\u001b[34mEpoch 44/200.. Train loss: 1.463.. Valid loss: 1.455.. Validation accuracy: 0.401\u001b[0m\n",
      "\u001b[34mEpoch: 44, NLLLoss: 1.4378422158105033\u001b[0m\n",
      "\u001b[34mEpoch 45/200.. Train loss: 1.438.. Valid loss: 1.500.. Validation accuracy: 0.372\u001b[0m\n",
      "\u001b[34mEpoch: 45, NLLLoss: 1.4569191932678223\u001b[0m\n",
      "\u001b[34mEpoch 46/200.. Train loss: 1.457.. Valid loss: 1.450.. Validation accuracy: 0.417\u001b[0m\n",
      "\u001b[34mEpoch: 46, NLLLoss: 1.445711306163243\u001b[0m\n",
      "\u001b[34mEpoch 47/200.. Train loss: 1.446.. Valid loss: 1.462.. Validation accuracy: 0.430\u001b[0m\n",
      "\u001b[34mEpoch: 47, NLLLoss: 1.4586969103131975\u001b[0m\n",
      "\u001b[34mEpoch 48/200.. Train loss: 1.459.. Valid loss: 1.480.. Validation accuracy: 0.407\u001b[0m\n",
      "\u001b[34mEpoch: 48, NLLLoss: 1.4807578836168562\u001b[0m\n",
      "\u001b[34mEpoch 49/200.. Train loss: 1.481.. Valid loss: 1.474.. Validation accuracy: 0.382\u001b[0m\n",
      "\u001b[34mEpoch: 49, NLLLoss: 1.4572017448289054\u001b[0m\n",
      "\u001b[34mEpoch 50/200.. Train loss: 1.457.. Valid loss: 1.404.. Validation accuracy: 0.438\u001b[0m\n",
      "\u001b[34mEpoch: 50, NLLLoss: 1.4456725546291895\u001b[0m\n",
      "\u001b[34mEpoch 51/200.. Train loss: 1.446.. Valid loss: 1.394.. Validation accuracy: 0.410\u001b[0m\n",
      "\u001b[34mEpoch: 51, NLLLoss: 1.4584663254874093\u001b[0m\n",
      "\u001b[34mEpoch 52/200.. Train loss: 1.458.. Valid loss: 1.436.. Validation accuracy: 0.394\u001b[0m\n",
      "\u001b[34mEpoch: 52, NLLLoss: 1.4459580864225114\u001b[0m\n",
      "\u001b[34mEpoch 53/200.. Train loss: 1.446.. Valid loss: 1.344.. Validation accuracy: 0.495\u001b[0m\n",
      "\u001b[34mEpoch: 53, NLLLoss: 1.457470987524305\u001b[0m\n",
      "\u001b[34mEpoch 54/200.. Train loss: 1.457.. Valid loss: 1.389.. Validation accuracy: 0.429\u001b[0m\n",
      "\u001b[34mEpoch: 54, NLLLoss: 1.4285566466195243\u001b[0m\n",
      "\u001b[34mEpoch 55/200.. Train loss: 1.429.. Valid loss: 1.473.. Validation accuracy: 0.441\u001b[0m\n",
      "\u001b[34mEpoch: 55, NLLLoss: 1.4362454925264632\u001b[0m\n",
      "\u001b[34mEpoch 56/200.. Train loss: 1.436.. Valid loss: 1.372.. Validation accuracy: 0.424\u001b[0m\n",
      "\u001b[34mEpoch: 56, NLLLoss: 1.4472482119287764\u001b[0m\n",
      "\u001b[34mEpoch 57/200.. Train loss: 1.447.. Valid loss: 2.354.. Validation accuracy: 0.228\u001b[0m\n",
      "\u001b[34mEpoch: 57, NLLLoss: 1.399234754698617\u001b[0m\n",
      "\u001b[34mEpoch 58/200.. Train loss: 1.399.. Valid loss: 1.346.. Validation accuracy: 0.448\u001b[0m\n",
      "\u001b[34mEpoch: 58, NLLLoss: 1.4071428435189384\u001b[0m\n",
      "\u001b[34mEpoch 59/200.. Train loss: 1.407.. Valid loss: 1.377.. Validation accuracy: 0.452\u001b[0m\n",
      "\u001b[34mEpoch: 59, NLLLoss: 1.4161895854132516\u001b[0m\n",
      "\u001b[34mEpoch 60/200.. Train loss: 1.416.. Valid loss: 1.377.. Validation accuracy: 0.448\u001b[0m\n",
      "\u001b[34mEpoch: 60, NLLLoss: 1.4245076434952872\u001b[0m\n",
      "\u001b[34mEpoch 61/200.. Train loss: 1.425.. Valid loss: 1.470.. Validation accuracy: 0.357\u001b[0m\n",
      "\u001b[34mEpoch: 61, NLLLoss: 1.4128782834325517\u001b[0m\n",
      "\u001b[34mEpoch 62/200.. Train loss: 1.413.. Valid loss: 1.507.. Validation accuracy: 0.424\u001b[0m\n",
      "\u001b[34mEpoch: 62, NLLLoss: 1.4192690423556737\u001b[0m\n",
      "\u001b[34mEpoch 63/200.. Train loss: 1.419.. Valid loss: 1.405.. Validation accuracy: 0.442\u001b[0m\n",
      "\u001b[34mEpoch: 63, NLLLoss: 1.4228082639830453\u001b[0m\n",
      "\u001b[34mEpoch 64/200.. Train loss: 1.423.. Valid loss: 1.406.. Validation accuracy: 0.439\u001b[0m\n",
      "\u001b[34mEpoch: 64, NLLLoss: 1.4212308015142168\u001b[0m\n",
      "\u001b[34mEpoch 65/200.. Train loss: 1.421.. Valid loss: 1.433.. Validation accuracy: 0.435\u001b[0m\n",
      "\u001b[34mEpoch: 65, NLLLoss: 1.4227580513272966\u001b[0m\n",
      "\u001b[34mEpoch 66/200.. Train loss: 1.423.. Valid loss: 1.471.. Validation accuracy: 0.418\u001b[0m\n",
      "\u001b[34mEpoch: 66, NLLLoss: 1.4271083559308733\u001b[0m\n",
      "\u001b[34mEpoch 67/200.. Train loss: 1.427.. Valid loss: 1.413.. Validation accuracy: 0.486\u001b[0m\n",
      "\u001b[34mEpoch: 67, NLLLoss: 1.4158875516482763\u001b[0m\n",
      "\u001b[34mEpoch 68/200.. Train loss: 1.416.. Valid loss: 1.377.. Validation accuracy: 0.453\u001b[0m\n",
      "\u001b[34mEpoch: 68, NLLLoss: 1.4216658643313818\u001b[0m\n",
      "\u001b[34mEpoch 69/200.. Train loss: 1.422.. Valid loss: 1.383.. Validation accuracy: 0.476\u001b[0m\n",
      "\u001b[34mEpoch: 69, NLLLoss: 1.4350777609007699\u001b[0m\n",
      "\u001b[34mEpoch 70/200.. Train loss: 1.435.. Valid loss: 1.385.. Validation accuracy: 0.468\u001b[0m\n",
      "\u001b[34mEpoch: 70, NLLLoss: 1.3919404659952437\u001b[0m\n",
      "\u001b[34mEpoch 71/200.. Train loss: 1.392.. Valid loss: 1.407.. Validation accuracy: 0.459\u001b[0m\n",
      "\u001b[34mEpoch: 71, NLLLoss: 1.3652635642460413\u001b[0m\n",
      "\u001b[34mEpoch 72/200.. Train loss: 1.365.. Valid loss: 1.472.. Validation accuracy: 0.423\u001b[0m\n",
      "\u001b[34mEpoch: 72, NLLLoss: 1.4235428827149528\u001b[0m\n",
      "\u001b[34mEpoch 73/200.. Train loss: 1.424.. Valid loss: 1.403.. Validation accuracy: 0.441\u001b[0m\n",
      "\u001b[34mEpoch: 73, NLLLoss: 1.41846068416323\u001b[0m\n",
      "\u001b[34mEpoch 74/200.. Train loss: 1.418.. Valid loss: 1.360.. Validation accuracy: 0.491\u001b[0m\n",
      "\u001b[34mEpoch: 74, NLLLoss: 1.3796742132731847\u001b[0m\n",
      "\u001b[34mEpoch 75/200.. Train loss: 1.380.. Valid loss: 1.339.. Validation accuracy: 0.497\u001b[0m\n",
      "\u001b[34mEpoch: 75, NLLLoss: 1.3673744457108634\u001b[0m\n",
      "\u001b[34mEpoch 76/200.. Train loss: 1.367.. Valid loss: 1.344.. Validation accuracy: 0.461\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mEpoch: 76, NLLLoss: 1.3838204060282027\u001b[0m\n",
      "\u001b[34mEpoch 77/200.. Train loss: 1.384.. Valid loss: 1.451.. Validation accuracy: 0.457\u001b[0m\n",
      "\u001b[34mEpoch: 77, NLLLoss: 1.3785628506115504\u001b[0m\n",
      "\u001b[34mEpoch 78/200.. Train loss: 1.379.. Valid loss: 1.412.. Validation accuracy: 0.458\u001b[0m\n",
      "\u001b[34mEpoch: 78, NLLLoss: 1.396346160343715\u001b[0m\n",
      "\u001b[34mEpoch 79/200.. Train loss: 1.396.. Valid loss: 1.324.. Validation accuracy: 0.474\u001b[0m\n",
      "\u001b[34mEpoch: 79, NLLLoss: 1.3827436055455888\u001b[0m\n",
      "\u001b[34mEpoch 80/200.. Train loss: 1.383.. Valid loss: 1.382.. Validation accuracy: 0.436\u001b[0m\n",
      "\u001b[34mEpoch: 80, NLLLoss: 1.320404393332345\u001b[0m\n",
      "\u001b[34mEpoch 81/200.. Train loss: 1.320.. Valid loss: 1.395.. Validation accuracy: 0.477\u001b[0m\n",
      "\u001b[34mEpoch: 81, NLLLoss: 1.3871208940233504\u001b[0m\n",
      "\u001b[34mEpoch 82/200.. Train loss: 1.387.. Valid loss: 1.391.. Validation accuracy: 0.466\u001b[0m\n",
      "\u001b[34mEpoch: 82, NLLLoss: 1.3640632118497575\u001b[0m\n",
      "\u001b[34mEpoch 83/200.. Train loss: 1.364.. Valid loss: 1.400.. Validation accuracy: 0.477\u001b[0m\n",
      "\u001b[34mEpoch: 83, NLLLoss: 1.3562518443380083\u001b[0m\n",
      "\u001b[34mEpoch 84/200.. Train loss: 1.356.. Valid loss: 1.410.. Validation accuracy: 0.424\u001b[0m\n",
      "\u001b[34mEpoch: 84, NLLLoss: 1.3558906657355172\u001b[0m\n",
      "\u001b[34mEpoch 85/200.. Train loss: 1.356.. Valid loss: 1.481.. Validation accuracy: 0.393\u001b[0m\n",
      "\u001b[34mEpoch: 85, NLLLoss: 1.3440484149115426\u001b[0m\n",
      "\u001b[34mEpoch 86/200.. Train loss: 1.344.. Valid loss: 1.395.. Validation accuracy: 0.427\u001b[0m\n",
      "\u001b[34mEpoch: 86, NLLLoss: 1.3846944911139352\u001b[0m\n",
      "\u001b[34mEpoch 87/200.. Train loss: 1.385.. Valid loss: 1.339.. Validation accuracy: 0.514\u001b[0m\n",
      "\u001b[34mEpoch: 87, NLLLoss: 1.3433684280940466\u001b[0m\n",
      "\u001b[34mEpoch 88/200.. Train loss: 1.343.. Valid loss: 1.383.. Validation accuracy: 0.442\u001b[0m\n",
      "\u001b[34mEpoch: 88, NLLLoss: 1.3567527447428023\u001b[0m\n",
      "\u001b[34mEpoch 89/200.. Train loss: 1.357.. Valid loss: 1.395.. Validation accuracy: 0.414\u001b[0m\n",
      "\u001b[34mEpoch: 89, NLLLoss: 1.3357671414102827\u001b[0m\n",
      "\u001b[34mEpoch 90/200.. Train loss: 1.336.. Valid loss: 1.345.. Validation accuracy: 0.501\u001b[0m\n",
      "\u001b[34mEpoch: 90, NLLLoss: 1.3905330896377563\u001b[0m\n",
      "\u001b[34mEpoch 91/200.. Train loss: 1.391.. Valid loss: 1.347.. Validation accuracy: 0.470\u001b[0m\n",
      "\u001b[34mEpoch: 91, NLLLoss: 1.3430780342647008\u001b[0m\n",
      "\u001b[34mEpoch 92/200.. Train loss: 1.343.. Valid loss: 1.379.. Validation accuracy: 0.461\u001b[0m\n",
      "\u001b[34mEpoch: 92, NLLLoss: 1.3403397457940238\u001b[0m\n",
      "\u001b[34mEpoch 93/200.. Train loss: 1.340.. Valid loss: 1.396.. Validation accuracy: 0.442\u001b[0m\n",
      "\u001b[34mEpoch: 93, NLLLoss: 1.3474921924727303\u001b[0m\n",
      "\u001b[34mEpoch 94/200.. Train loss: 1.347.. Valid loss: 1.332.. Validation accuracy: 0.480\u001b[0m\n",
      "\u001b[34mEpoch: 94, NLLLoss: 1.32472425699234\u001b[0m\n",
      "\u001b[34mEpoch 95/200.. Train loss: 1.325.. Valid loss: 1.324.. Validation accuracy: 0.518\u001b[0m\n",
      "\u001b[34mEpoch: 95, NLLLoss: 1.3257332018443517\u001b[0m\n",
      "\u001b[34mEpoch 96/200.. Train loss: 1.326.. Valid loss: 1.706.. Validation accuracy: 0.397\u001b[0m\n",
      "\u001b[34mEpoch: 96, NLLLoss: 1.2979857666151864\u001b[0m\n",
      "\u001b[34mEpoch 97/200.. Train loss: 1.298.. Valid loss: 1.373.. Validation accuracy: 0.490\u001b[0m\n",
      "\u001b[34mEpoch: 97, NLLLoss: 1.3128278340612138\u001b[0m\n",
      "\u001b[34mEpoch 98/200.. Train loss: 1.313.. Valid loss: 1.356.. Validation accuracy: 0.478\u001b[0m\n",
      "\u001b[34mEpoch: 98, NLLLoss: 1.3059893591063363\u001b[0m\n",
      "\u001b[34mEpoch 99/200.. Train loss: 1.306.. Valid loss: 1.296.. Validation accuracy: 0.487\u001b[0m\n",
      "\u001b[34mEpoch: 99, NLLLoss: 1.2777176329067774\u001b[0m\n",
      "\u001b[34mEpoch 100/200.. Train loss: 1.278.. Valid loss: 1.335.. Validation accuracy: 0.506\u001b[0m\n",
      "\u001b[34mEpoch: 100, NLLLoss: 1.2974283184323991\u001b[0m\n",
      "\u001b[34mEpoch 101/200.. Train loss: 1.297.. Valid loss: 1.340.. Validation accuracy: 0.480\u001b[0m\n",
      "\u001b[34mEpoch: 101, NLLLoss: 1.318505585193634\u001b[0m\n",
      "\u001b[34mEpoch 102/200.. Train loss: 1.319.. Valid loss: 1.405.. Validation accuracy: 0.436\u001b[0m\n",
      "\u001b[34mEpoch: 102, NLLLoss: 1.292863769190652\u001b[0m\n",
      "\u001b[34mEpoch 103/200.. Train loss: 1.293.. Valid loss: 1.336.. Validation accuracy: 0.457\u001b[0m\n",
      "\u001b[34mEpoch: 103, NLLLoss: 1.3463136298315865\u001b[0m\n",
      "\u001b[34mEpoch 104/200.. Train loss: 1.346.. Valid loss: 1.335.. Validation accuracy: 0.493\u001b[0m\n",
      "\u001b[34mEpoch: 104, NLLLoss: 1.3030022382736206\u001b[0m\n",
      "\u001b[34mEpoch 105/200.. Train loss: 1.303.. Valid loss: 1.382.. Validation accuracy: 0.463\u001b[0m\n",
      "\u001b[34mEpoch: 105, NLLLoss: 1.2752898505755834\u001b[0m\n",
      "\u001b[34mEpoch 106/200.. Train loss: 1.275.. Valid loss: 1.396.. Validation accuracy: 0.456\u001b[0m\n",
      "\u001b[34mEpoch: 106, NLLLoss: 1.2882253527641296\u001b[0m\n",
      "\u001b[34mEpoch 107/200.. Train loss: 1.288.. Valid loss: 1.444.. Validation accuracy: 0.465\u001b[0m\n",
      "\u001b[34mEpoch: 107, NLLLoss: 1.2832629254886083\u001b[0m\n",
      "\u001b[34mEpoch 108/200.. Train loss: 1.283.. Valid loss: 1.341.. Validation accuracy: 0.504\u001b[0m\n",
      "\u001b[34mEpoch: 108, NLLLoss: 1.320244346346174\u001b[0m\n",
      "\u001b[34mEpoch 109/200.. Train loss: 1.320.. Valid loss: 1.392.. Validation accuracy: 0.461\u001b[0m\n",
      "\u001b[34mEpoch: 109, NLLLoss: 1.2925392133849007\u001b[0m\n",
      "\u001b[34mEpoch 110/200.. Train loss: 1.293.. Valid loss: 1.463.. Validation accuracy: 0.384\u001b[0m\n",
      "\u001b[34mEpoch: 110, NLLLoss: 1.3195651939937048\u001b[0m\n",
      "\u001b[34mEpoch 111/200.. Train loss: 1.320.. Valid loss: 1.315.. Validation accuracy: 0.498\u001b[0m\n",
      "\u001b[34mEpoch: 111, NLLLoss: 1.3142860106059484\u001b[0m\n",
      "\u001b[34mEpoch 112/200.. Train loss: 1.314.. Valid loss: 1.412.. Validation accuracy: 0.422\u001b[0m\n",
      "\u001b[34mEpoch: 112, NLLLoss: 1.3302891509873527\u001b[0m\n",
      "\u001b[34mEpoch 113/200.. Train loss: 1.330.. Valid loss: 1.399.. Validation accuracy: 0.467\u001b[0m\n",
      "\u001b[34mEpoch: 113, NLLLoss: 1.2852485605648585\u001b[0m\n",
      "\u001b[34mEpoch 114/200.. Train loss: 1.285.. Valid loss: 1.328.. Validation accuracy: 0.504\u001b[0m\n",
      "\u001b[34mEpoch: 114, NLLLoss: 1.288065799645015\u001b[0m\n",
      "\u001b[34mEpoch 115/200.. Train loss: 1.288.. Valid loss: 1.328.. Validation accuracy: 0.495\u001b[0m\n",
      "\u001b[34mEpoch: 115, NLLLoss: 1.2795732957976205\u001b[0m\n",
      "\u001b[34mEpoch 116/200.. Train loss: 1.280.. Valid loss: 1.266.. Validation accuracy: 0.586\u001b[0m\n",
      "\u001b[34mEpoch: 116, NLLLoss: 1.289850720337459\u001b[0m\n",
      "\u001b[34mEpoch 117/200.. Train loss: 1.290.. Valid loss: 1.305.. Validation accuracy: 0.508\u001b[0m\n",
      "\u001b[34mEpoch: 117, NLLLoss: 1.2481146539960588\u001b[0m\n",
      "\u001b[34mEpoch 118/200.. Train loss: 1.248.. Valid loss: 1.244.. Validation accuracy: 0.534\u001b[0m\n",
      "\u001b[34mEpoch: 118, NLLLoss: 1.2761746559824263\u001b[0m\n",
      "\u001b[34mEpoch 119/200.. Train loss: 1.276.. Valid loss: 1.253.. Validation accuracy: 0.546\u001b[0m\n",
      "\u001b[34mEpoch: 119, NLLLoss: 1.243871910231454\u001b[0m\n",
      "\u001b[34mEpoch 120/200.. Train loss: 1.244.. Valid loss: 1.293.. Validation accuracy: 0.503\u001b[0m\n",
      "\u001b[34mEpoch: 120, NLLLoss: 1.279991124357496\u001b[0m\n",
      "\u001b[34mEpoch 121/200.. Train loss: 1.280.. Valid loss: 1.327.. Validation accuracy: 0.518\u001b[0m\n",
      "\u001b[34mEpoch: 121, NLLLoss: 1.249492347240448\u001b[0m\n",
      "\u001b[34mEpoch 122/200.. Train loss: 1.249.. Valid loss: 1.244.. Validation accuracy: 0.542\u001b[0m\n",
      "\u001b[34mEpoch: 122, NLLLoss: 1.286767636026655\u001b[0m\n",
      "\u001b[34mEpoch 123/200.. Train loss: 1.287.. Valid loss: 1.395.. Validation accuracy: 0.428\u001b[0m\n",
      "\u001b[34mEpoch: 123, NLLLoss: 1.2609690512929643\u001b[0m\n",
      "\u001b[34mEpoch 124/200.. Train loss: 1.261.. Valid loss: 1.432.. Validation accuracy: 0.447\u001b[0m\n",
      "\u001b[34mEpoch: 124, NLLLoss: 1.2457664396081651\u001b[0m\n",
      "\u001b[34mEpoch 125/200.. Train loss: 1.246.. Valid loss: 1.331.. Validation accuracy: 0.505\u001b[0m\n",
      "\u001b[34mEpoch: 125, NLLLoss: 1.2909058502742223\u001b[0m\n",
      "\u001b[34mEpoch 126/200.. Train loss: 1.291.. Valid loss: 1.310.. Validation accuracy: 0.492\u001b[0m\n",
      "\u001b[34mEpoch: 126, NLLLoss: 1.2200372985431127\u001b[0m\n",
      "\u001b[34mEpoch 127/200.. Train loss: 1.220.. Valid loss: 1.288.. Validation accuracy: 0.488\u001b[0m\n",
      "\u001b[34mEpoch: 127, NLLLoss: 1.2448742389678955\u001b[0m\n",
      "\u001b[34mEpoch 128/200.. Train loss: 1.245.. Valid loss: 1.296.. Validation accuracy: 0.503\u001b[0m\n",
      "\u001b[34mEpoch: 128, NLLLoss: 1.2529518604278564\u001b[0m\n",
      "\u001b[34mEpoch 129/200.. Train loss: 1.253.. Valid loss: 1.317.. Validation accuracy: 0.462\u001b[0m\n",
      "\u001b[34mEpoch: 129, NLLLoss: 1.2699490785598755\u001b[0m\n",
      "\u001b[34mEpoch 130/200.. Train loss: 1.270.. Valid loss: 1.305.. Validation accuracy: 0.464\u001b[0m\n",
      "\u001b[34mEpoch: 130, NLLLoss: 1.27817074741636\u001b[0m\n",
      "\u001b[34mEpoch 131/200.. Train loss: 1.278.. Valid loss: 1.331.. Validation accuracy: 0.456\u001b[0m\n",
      "\u001b[34mEpoch: 131, NLLLoss: 1.232163437775203\u001b[0m\n",
      "\u001b[34mEpoch 132/200.. Train loss: 1.232.. Valid loss: 1.262.. Validation accuracy: 0.530\u001b[0m\n",
      "\u001b[34mEpoch: 132, NLLLoss: 1.235250643321446\u001b[0m\n",
      "\u001b[34mEpoch 133/200.. Train loss: 1.235.. Valid loss: 1.322.. Validation accuracy: 0.499\u001b[0m\n",
      "\u001b[34mEpoch: 133, NLLLoss: 1.2340621522494726\u001b[0m\n",
      "\u001b[34mEpoch 134/200.. Train loss: 1.234.. Valid loss: 1.418.. Validation accuracy: 0.456\u001b[0m\n",
      "\u001b[34mEpoch: 134, NLLLoss: 1.251546357359205\u001b[0m\n",
      "\u001b[34mEpoch 135/200.. Train loss: 1.252.. Valid loss: 1.279.. Validation accuracy: 0.520\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mEpoch: 135, NLLLoss: 1.2053891207490648\u001b[0m\n",
      "\u001b[34mEpoch 136/200.. Train loss: 1.205.. Valid loss: 1.713.. Validation accuracy: 0.434\u001b[0m\n",
      "\u001b[34mEpoch: 136, NLLLoss: 1.211926817893982\u001b[0m\n",
      "\u001b[34mEpoch 137/200.. Train loss: 1.212.. Valid loss: 1.323.. Validation accuracy: 0.501\u001b[0m\n",
      "\u001b[34mEpoch: 137, NLLLoss: 1.2358261431966509\u001b[0m\n",
      "\u001b[34mEpoch 138/200.. Train loss: 1.236.. Valid loss: 1.378.. Validation accuracy: 0.464\u001b[0m\n",
      "\u001b[34mEpoch: 138, NLLLoss: 1.2551274384771074\u001b[0m\n",
      "\u001b[34mEpoch 139/200.. Train loss: 1.255.. Valid loss: 1.283.. Validation accuracy: 0.522\u001b[0m\n",
      "\u001b[34mEpoch: 139, NLLLoss: 1.183439735855375\u001b[0m\n",
      "\u001b[34mEpoch 140/200.. Train loss: 1.183.. Valid loss: 1.393.. Validation accuracy: 0.465\u001b[0m\n",
      "\u001b[34mEpoch: 140, NLLLoss: 1.225750914641789\u001b[0m\n",
      "\u001b[34mEpoch 141/200.. Train loss: 1.226.. Valid loss: 1.283.. Validation accuracy: 0.516\u001b[0m\n",
      "\u001b[34mEpoch: 141, NLLLoss: 1.2028886420386178\u001b[0m\n",
      "\u001b[34mEpoch 142/200.. Train loss: 1.203.. Valid loss: 1.325.. Validation accuracy: 0.500\u001b[0m\n",
      "\u001b[34mEpoch: 142, NLLLoss: 1.249782383441925\u001b[0m\n",
      "\u001b[34mEpoch 143/200.. Train loss: 1.250.. Valid loss: 1.372.. Validation accuracy: 0.496\u001b[0m\n",
      "\u001b[34mEpoch: 143, NLLLoss: 1.2467556170054845\u001b[0m\n",
      "\u001b[34mEpoch 144/200.. Train loss: 1.247.. Valid loss: 1.368.. Validation accuracy: 0.481\u001b[0m\n",
      "\u001b[34mEpoch: 144, NLLLoss: 1.1984005059514726\u001b[0m\n",
      "\u001b[34mEpoch 145/200.. Train loss: 1.198.. Valid loss: 1.309.. Validation accuracy: 0.530\u001b[0m\n",
      "\u001b[34mEpoch: 145, NLLLoss: 1.1737881984029497\u001b[0m\n",
      "\u001b[34mEpoch 146/200.. Train loss: 1.174.. Valid loss: 1.285.. Validation accuracy: 0.521\u001b[0m\n",
      "\u001b[34mEpoch: 146, NLLLoss: 1.1785359850951604\u001b[0m\n",
      "\u001b[34mEpoch 147/200.. Train loss: 1.179.. Valid loss: 1.422.. Validation accuracy: 0.459\u001b[0m\n",
      "\u001b[34mEpoch: 147, NLLLoss: 1.1886684468814306\u001b[0m\n",
      "\u001b[34mEpoch 148/200.. Train loss: 1.189.. Valid loss: 1.323.. Validation accuracy: 0.485\u001b[0m\n",
      "\u001b[34mEpoch: 148, NLLLoss: 1.1933705977031164\u001b[0m\n",
      "\u001b[34mEpoch 149/200.. Train loss: 1.193.. Valid loss: 1.306.. Validation accuracy: 0.503\u001b[0m\n",
      "\u001b[34mEpoch: 149, NLLLoss: 1.2028431807245528\u001b[0m\n",
      "\u001b[34mEpoch 150/200.. Train loss: 1.203.. Valid loss: 1.316.. Validation accuracy: 0.525\u001b[0m\n",
      "\u001b[34mEpoch: 150, NLLLoss: 1.2028884376798357\u001b[0m\n",
      "\u001b[34mEpoch 151/200.. Train loss: 1.203.. Valid loss: 1.717.. Validation accuracy: 0.382\u001b[0m\n",
      "\u001b[34mEpoch: 151, NLLLoss: 1.2462791630199976\u001b[0m\n",
      "\u001b[34mEpoch 152/200.. Train loss: 1.246.. Valid loss: 1.262.. Validation accuracy: 0.554\u001b[0m\n",
      "\u001b[34mEpoch: 152, NLLLoss: 1.2187309776033675\u001b[0m\n",
      "\u001b[34mEpoch 153/200.. Train loss: 1.219.. Valid loss: 1.299.. Validation accuracy: 0.525\u001b[0m\n",
      "\u001b[34mEpoch: 153, NLLLoss: 1.21439494405474\u001b[0m\n",
      "\u001b[34mEpoch 154/200.. Train loss: 1.214.. Valid loss: 1.312.. Validation accuracy: 0.504\u001b[0m\n",
      "\u001b[34mEpoch: 154, NLLLoss: 1.2429618750299727\u001b[0m\n",
      "\u001b[34mEpoch 155/200.. Train loss: 1.243.. Valid loss: 1.246.. Validation accuracy: 0.563\u001b[0m\n",
      "\u001b[34mEpoch: 155, NLLLoss: 1.2139515280723572\u001b[0m\n",
      "\u001b[34mEpoch 156/200.. Train loss: 1.214.. Valid loss: 1.725.. Validation accuracy: 0.430\u001b[0m\n",
      "\u001b[34mEpoch: 156, NLLLoss: 1.1606826015881129\u001b[0m\n",
      "\u001b[34mEpoch 157/200.. Train loss: 1.161.. Valid loss: 1.252.. Validation accuracy: 0.525\u001b[0m\n",
      "\u001b[34mEpoch: 157, NLLLoss: 1.1950211780411857\u001b[0m\n",
      "\u001b[34mEpoch 158/200.. Train loss: 1.195.. Valid loss: 1.241.. Validation accuracy: 0.536\u001b[0m\n",
      "\u001b[34mEpoch: 158, NLLLoss: 1.1839272379875183\u001b[0m\n",
      "\u001b[34mEpoch 159/200.. Train loss: 1.184.. Valid loss: 1.308.. Validation accuracy: 0.512\u001b[0m\n",
      "\u001b[34mEpoch: 159, NLLLoss: 1.2145522747720991\u001b[0m\n",
      "\u001b[34mEpoch 160/200.. Train loss: 1.215.. Valid loss: 1.290.. Validation accuracy: 0.499\u001b[0m\n",
      "\u001b[34mEpoch: 160, NLLLoss: 1.2085531949996948\u001b[0m\n",
      "\u001b[34mEpoch 161/200.. Train loss: 1.209.. Valid loss: 1.240.. Validation accuracy: 0.541\u001b[0m\n",
      "\u001b[34mEpoch: 161, NLLLoss: 1.1930891019957406\u001b[0m\n",
      "\u001b[34mEpoch 162/200.. Train loss: 1.193.. Valid loss: 1.261.. Validation accuracy: 0.565\u001b[0m\n",
      "\u001b[34mEpoch: 162, NLLLoss: 1.2076167123658317\u001b[0m\n",
      "\u001b[34mEpoch 163/200.. Train loss: 1.208.. Valid loss: 1.266.. Validation accuracy: 0.491\u001b[0m\n",
      "\u001b[34mEpoch: 163, NLLLoss: 1.2097571917942591\u001b[0m\n",
      "\u001b[34mEpoch 164/200.. Train loss: 1.210.. Valid loss: 1.325.. Validation accuracy: 0.515\u001b[0m\n",
      "\u001b[34mEpoch: 164, NLLLoss: 1.2174987622669764\u001b[0m\n",
      "\u001b[34mEpoch 165/200.. Train loss: 1.217.. Valid loss: 1.497.. Validation accuracy: 0.436\u001b[0m\n",
      "\u001b[34mEpoch: 165, NLLLoss: 1.1974391341209412\u001b[0m\n",
      "\u001b[34mEpoch 166/200.. Train loss: 1.197.. Valid loss: 1.376.. Validation accuracy: 0.488\u001b[0m\n",
      "\u001b[34mEpoch: 166, NLLLoss: 1.225106486252376\u001b[0m\n",
      "\u001b[34mEpoch 167/200.. Train loss: 1.225.. Valid loss: 1.247.. Validation accuracy: 0.532\u001b[0m\n",
      "\u001b[34mEpoch: 167, NLLLoss: 1.1512626792703355\u001b[0m\n",
      "\u001b[34mEpoch 168/200.. Train loss: 1.151.. Valid loss: 1.222.. Validation accuracy: 0.544\u001b[0m\n",
      "\u001b[34mEpoch: 168, NLLLoss: 1.1390772461891174\u001b[0m\n",
      "\u001b[34mEpoch 169/200.. Train loss: 1.139.. Valid loss: 1.324.. Validation accuracy: 0.509\u001b[0m\n",
      "\u001b[34mEpoch: 169, NLLLoss: 1.1681567898818426\u001b[0m\n",
      "\u001b[34mEpoch 170/200.. Train loss: 1.168.. Valid loss: 1.283.. Validation accuracy: 0.519\u001b[0m\n",
      "\u001b[34mEpoch: 170, NLLLoss: 1.2013150879314967\u001b[0m\n",
      "\u001b[34mEpoch 171/200.. Train loss: 1.201.. Valid loss: 1.198.. Validation accuracy: 0.523\u001b[0m\n",
      "\u001b[34mEpoch: 171, NLLLoss: 1.1941098996571131\u001b[0m\n",
      "\u001b[34mEpoch 172/200.. Train loss: 1.194.. Valid loss: 1.249.. Validation accuracy: 0.538\u001b[0m\n",
      "\u001b[34mEpoch: 172, NLLLoss: 1.176046005317143\u001b[0m\n",
      "\u001b[34mEpoch 173/200.. Train loss: 1.176.. Valid loss: 1.272.. Validation accuracy: 0.550\u001b[0m\n",
      "\u001b[34mEpoch: 173, NLLLoss: 1.194677003792354\u001b[0m\n",
      "\u001b[34mEpoch 174/200.. Train loss: 1.195.. Valid loss: 1.266.. Validation accuracy: 0.515\u001b[0m\n",
      "\u001b[34mEpoch: 174, NLLLoss: 1.159664945943015\u001b[0m\n",
      "\u001b[34mEpoch 175/200.. Train loss: 1.160.. Valid loss: 1.274.. Validation accuracy: 0.517\u001b[0m\n",
      "\u001b[34mEpoch: 175, NLLLoss: 1.2111927952085222\u001b[0m\n",
      "\u001b[34mEpoch 176/200.. Train loss: 1.211.. Valid loss: 1.315.. Validation accuracy: 0.542\u001b[0m\n",
      "\u001b[34mEpoch: 176, NLLLoss: 1.1815783764634813\u001b[0m\n",
      "\u001b[34mEpoch 177/200.. Train loss: 1.182.. Valid loss: 1.270.. Validation accuracy: 0.517\u001b[0m\n",
      "\u001b[34mEpoch: 177, NLLLoss: 1.1332993507385254\u001b[0m\n",
      "\u001b[34mEpoch 178/200.. Train loss: 1.133.. Valid loss: 1.329.. Validation accuracy: 0.517\u001b[0m\n",
      "\u001b[34mEpoch: 178, NLLLoss: 1.1398997562272208\u001b[0m\n",
      "\u001b[34mEpoch 179/200.. Train loss: 1.140.. Valid loss: 1.297.. Validation accuracy: 0.514\u001b[0m\n",
      "\u001b[34mEpoch: 179, NLLLoss: 1.123459871326174\u001b[0m\n",
      "\u001b[34mEpoch 180/200.. Train loss: 1.123.. Valid loss: 1.230.. Validation accuracy: 0.548\u001b[0m\n",
      "\u001b[34mEpoch: 180, NLLLoss: 1.1501205010073525\u001b[0m\n",
      "\u001b[34mEpoch 181/200.. Train loss: 1.150.. Valid loss: 1.250.. Validation accuracy: 0.554\u001b[0m\n",
      "\u001b[34mEpoch: 181, NLLLoss: 1.0982277946812766\u001b[0m\n",
      "\u001b[34mEpoch 182/200.. Train loss: 1.098.. Valid loss: 1.287.. Validation accuracy: 0.583\u001b[0m\n",
      "\u001b[34mEpoch: 182, NLLLoss: 1.1613372095993586\u001b[0m\n",
      "\u001b[34mEpoch 183/200.. Train loss: 1.161.. Valid loss: 1.287.. Validation accuracy: 0.534\u001b[0m\n",
      "\u001b[34mEpoch: 183, NLLLoss: 1.1545273193291254\u001b[0m\n",
      "\u001b[34mEpoch 184/200.. Train loss: 1.155.. Valid loss: 1.330.. Validation accuracy: 0.507\u001b[0m\n",
      "\u001b[34mEpoch: 184, NLLLoss: 1.1661535927227564\u001b[0m\n",
      "\u001b[34mEpoch 185/200.. Train loss: 1.166.. Valid loss: 1.266.. Validation accuracy: 0.536\u001b[0m\n",
      "\u001b[34mEpoch: 185, NLLLoss: 1.170476108789444\u001b[0m\n",
      "\u001b[34mEpoch 186/200.. Train loss: 1.170.. Valid loss: 1.289.. Validation accuracy: 0.527\u001b[0m\n",
      "\u001b[34mEpoch: 186, NLLLoss: 1.1725539990833826\u001b[0m\n",
      "\u001b[34mEpoch 187/200.. Train loss: 1.173.. Valid loss: 1.363.. Validation accuracy: 0.496\u001b[0m\n",
      "\u001b[34mEpoch: 187, NLLLoss: 1.1509129064423698\u001b[0m\n",
      "\u001b[34mEpoch 188/200.. Train loss: 1.151.. Valid loss: 1.330.. Validation accuracy: 0.504\u001b[0m\n",
      "\u001b[34mEpoch: 188, NLLLoss: 1.1540378545011793\u001b[0m\n",
      "\u001b[34mEpoch 189/200.. Train loss: 1.154.. Valid loss: 1.258.. Validation accuracy: 0.536\u001b[0m\n",
      "\u001b[34mEpoch: 189, NLLLoss: 1.1760457839284624\u001b[0m\n",
      "\u001b[34mEpoch 190/200.. Train loss: 1.176.. Valid loss: 1.313.. Validation accuracy: 0.557\u001b[0m\n",
      "\u001b[34mEpoch: 190, NLLLoss: 1.140833216054099\u001b[0m\n",
      "\u001b[34mEpoch 191/200.. Train loss: 1.141.. Valid loss: 1.279.. Validation accuracy: 0.514\u001b[0m\n",
      "\u001b[34mEpoch: 191, NLLLoss: 1.1149876245430537\u001b[0m\n",
      "\u001b[34mEpoch 192/200.. Train loss: 1.115.. Valid loss: 1.381.. Validation accuracy: 0.541\u001b[0m\n",
      "\u001b[34mEpoch: 192, NLLLoss: 1.1530229662145888\u001b[0m\n",
      "\u001b[34mEpoch 193/200.. Train loss: 1.153.. Valid loss: 1.292.. Validation accuracy: 0.541\u001b[0m\n",
      "\u001b[34mEpoch: 193, NLLLoss: 1.1274700377668654\u001b[0m\n",
      "\u001b[34mEpoch 194/200.. Train loss: 1.127.. Valid loss: 1.254.. Validation accuracy: 0.553\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mEpoch: 194, NLLLoss: 1.12204144682203\u001b[0m\n",
      "\u001b[34mEpoch 195/200.. Train loss: 1.122.. Valid loss: 1.334.. Validation accuracy: 0.507\u001b[0m\n",
      "\u001b[34mEpoch: 195, NLLLoss: 1.0925083756446838\u001b[0m\n",
      "\u001b[34mEpoch 196/200.. Train loss: 1.093.. Valid loss: 1.214.. Validation accuracy: 0.566\u001b[0m\n",
      "\u001b[34mEpoch: 196, NLLLoss: 1.1931924266474587\u001b[0m\n",
      "\u001b[34mEpoch 197/200.. Train loss: 1.193.. Valid loss: 1.328.. Validation accuracy: 0.516\u001b[0m\n",
      "\u001b[34mEpoch: 197, NLLLoss: 1.1347325869968958\u001b[0m\n",
      "\u001b[34mEpoch 198/200.. Train loss: 1.135.. Valid loss: 1.279.. Validation accuracy: 0.531\u001b[0m\n",
      "\u001b[34mEpoch: 198, NLLLoss: 1.1133912418569838\u001b[0m\n",
      "\u001b[34mEpoch 199/200.. Train loss: 1.113.. Valid loss: 1.291.. Validation accuracy: 0.551\u001b[0m\n",
      "\u001b[34mEpoch: 199, NLLLoss: 1.133009203842708\u001b[0m\n",
      "\u001b[34mEpoch 200/200.. Train loss: 1.133.. Valid loss: 1.243.. Validation accuracy: 0.553\u001b[0m\n",
      "\u001b[34mEpoch: 200, NLLLoss: 1.1060068011283875\u001b[0m\n",
      "\u001b[34mEpoch 201/200.. Train loss: 1.106.. Valid loss: 1.304.. Validation accuracy: 0.532\u001b[0m\n",
      "\u001b[34m2020-12-15 16:54:34,113 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-12-15 16:55:27 Uploading - Uploading generated training model\n",
      "2020-12-15 16:55:47 Completed - Training job completed\n",
      "ProfilerReport-1608048905: IssuesFound\n",
      "Training seconds: 2227\n",
      "Billable seconds: 2227\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({'training':output_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2.698.. Test accuracy: 0.284\n"
     ]
    }
   ],
   "source": [
    "model = EmotionClassifier()\n",
    "\n",
    "model_dir = \"./\"\n",
    "model_path = os.path.join(model_dir, 'model.pth')\n",
    "with open(model_path, 'rb') as f:\n",
    "    model.load_state_dict(torch.load(f))\n",
    "#model =model.load_state_dict(torch.load())\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#model = vgg16\n",
    "model.to(device)\n",
    "test_loss = 0\n",
    "accuracy = 0\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "model.to(device)\n",
    "test_loss = 0\n",
    "accuracy = 0\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for inputs, labels in testloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        logps = model.forward(inputs)\n",
    "        y_true.append(labels.item())\n",
    "        m = nn.LogSoftmax(dim=1)\n",
    "        batch_loss = loss_fn(m(logps), labels)\n",
    "\n",
    "        test_loss += batch_loss.item()\n",
    "        #accuracy = 0\n",
    "        # Calculate accuracy\n",
    "        ps = torch.exp(logps)\n",
    "        top_p, top_class = ps.topk(1, dim=1)\n",
    "        y_pred.append(top_class.item())\n",
    "        equals = top_class == labels.view(*top_class.shape)\n",
    "        accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "\n",
    "print(f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
    "\tf\"Test accuracy: {accuracy/len(testloader):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This test accuracy has been obtained at the very first trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'estimator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-b7af67daa923>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msagemaker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtuner\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHyperparameterTuner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mContinuousParameter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIntegerParameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m my_tuner = HyperparameterTuner(estimator=estimator,  # previously-configured Estimator object\n\u001b[0m\u001b[1;32m      3\u001b[0m                                \u001b[0mobjective_metric_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'validation-accuracy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                hyperparameter_ranges={'learning_rate': ContinuousParameter(0.001, 0.01)\n\u001b[1;32m      5\u001b[0m                                                      },\n",
      "\u001b[0;31mNameError\u001b[0m: name 'estimator' is not defined"
     ]
    }
   ],
   "source": [
    "from sagemaker.tuner import HyperparameterTuner, ContinuousParameter, IntegerParameter\n",
    "my_tuner = HyperparameterTuner(estimator=estimator,  # previously-configured Estimator object\n",
    "                               objective_metric_name='validation-accuracy',\n",
    "                               hyperparameter_ranges={'learning_rate': ContinuousParameter(0.001, 0.01)\n",
    "                                                     },\n",
    "                               metric_definitions=[{'Name': 'validation-accuracy', 'Regex': 'Validation accuracy: (\\d\\.\\d+)'}],\n",
    "                               max_jobs=10,\n",
    "                               max_parallel_jobs=3,\n",
    "                               early_stopping_type='Auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................__s\n"
     ]
    }
   ],
   "source": [
    "my_tuner.fit({'training':output_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion-detection/modelOutput/sagemaker-pytorch-2020-12-15-16-15-05-577/output/model.tar.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2304"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the name of the training job, \n",
    "training_job_name='sagemaker-pytorch-2020-12-15-16-15-05-577'\n",
    "\n",
    "# where the model is saved, by default\n",
    "model_key = os.path.join(prefix, \"modelOutput\",training_job_name, 'output/model.tar.gz')\n",
    "print(model_key)\n",
    "\n",
    "#s3://sagemaker-us-east-2-769207522942/emotion-detection/output/sagemaker-pytorch-2020-12-05-09-07-48-004/output/model.tar.gz \n",
    "# download and unzip model\n",
    "boto3.resource('s3').Bucket(bucket).download_file(model_key, 'model.tar.gz')\n",
    "\n",
    "# unzipping as model_algo-1\n",
    "os.system('tar -zxvf model.tar.gz')\n",
    "os.system('unzip model_algo-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -f model.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.519.. Test accuracy: 0.495\n"
     ]
    }
   ],
   "source": [
    "#from sagemaker.pytorch import PyTorchModel\n",
    "#model = PyTorchModel(model_data=estimator.model_data,\n",
    "#                     role = role,\n",
    "#                     framework_version='1.0.0',\n",
    "#                     py_version='py3')\n",
    "\"\"\"model = EmotionClassifier()\n",
    "\n",
    "    # Load the store model parameters.\n",
    "    model_path = os.path.join(model_dir, 'model.pth')\n",
    "    with open(model_path, 'rb') as f:\n",
    "        model.load_state_dict(torch.load(f))\n",
    "\n",
    "    model.to(device).eval()\"\"\"\n",
    "y_true = []\n",
    "y_pred = []\n",
    "from model import EmotionClassifier\n",
    "model = EmotionClassifier()\n",
    "model_dir = \"./\"\n",
    "model_path = os.path.join(model_dir, 'model.pth')\n",
    "with open(model_path, 'rb') as f:\n",
    "    model.load_state_dict(torch.load(f))\n",
    "#model =model.load_state_dict(torch.load())\n",
    "model.to(device)\n",
    "test_loss = 0\n",
    "accuracy = 0\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for inputs, labels in testloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        logps = model.forward(inputs)\n",
    "        l = [element.item() for element in labels.flatten()]#labels.flatten().item().tolist()\n",
    "        y_true.append(l)\n",
    "        m = nn.LogSoftmax(dim=1)\n",
    "        batch_loss = loss_fn(m(logps), labels)\n",
    "\n",
    "        test_loss += batch_loss.item()\n",
    "        #accuracy = 0\n",
    "        # Calculate accuracy\n",
    "        ps = torch.exp(logps)\n",
    "        top_p, top_class = ps.topk(1, dim=1)\n",
    "        l = [element.item() for element in top_class.flatten()]\n",
    "        y_pred.append(l)\n",
    "        equals = top_class == labels.view(*top_class.shape)\n",
    "        accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "\n",
    "print(f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
    "\tf\"Test accuracy: {accuracy/len(testloader):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.57      0.31      0.40        52\n",
      "     disgust       0.48      0.60      0.54        43\n",
      "        fear       0.00      0.00      0.00         6\n",
      "   happiness       0.51      0.79      0.62        99\n",
      "     neutral       0.38      0.49      0.43        91\n",
      "     sadness       0.38      0.15      0.22        52\n",
      "    surprise       0.59      0.39      0.47        83\n",
      "\n",
      "    accuracy                           0.48       426\n",
      "   macro avg       0.42      0.39      0.38       426\n",
      "weighted avg       0.48      0.48      0.46       426\n",
      "\n",
      "Confusion Matrix\n",
      "[[16  2  0 10 15  3  6]\n",
      " [ 1 26  0  6  1  8  1]\n",
      " [ 0  4  0  0  2  0  0]\n",
      " [ 3  4  0 78 11  1  2]\n",
      " [ 2  3  0 30 45  0 11]\n",
      " [ 2 14  0 12 14  8  2]\n",
      " [ 4  1  0 16 29  1 32]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#class_labels = {v: k for k, v in class_labels.items()}\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "target_names = (test_data.class_to_idx).keys()\n",
    "print('Classification Report')\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "#y = np.argmax(y_pred, axis=1)\n",
    "cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print('Confusion Matrix')\n",
    "print(cnf_matrix)\n",
    "plt.imshow(cnf_matrix, interpolation='nearest')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(target_names))\n",
    "_ = plt.xticks(tick_marks, target_names, rotation=90)\n",
    "_ = plt.yticks(tick_marks, target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmotionClassifier(\n",
      "  (cnn_layers): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Dropout(p=0.25, inplace=False)\n",
      "    (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): Dropout(p=0.25, inplace=False)\n",
      "    (10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Dropout(p=0.25, inplace=False)\n",
      "    (15): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (19): Dropout(p=0.25, inplace=False)\n",
      "  )\n",
      "  (linear_layers): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=512, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=256, out_features=84, bias=True)\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Dropout(p=0.5, inplace=False)\n",
      "    (9): Linear(in_features=84, out_features=7, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\" to /home/ec2-user/.cache/torch/checkpoints/alexnet-owt-4df8aa71.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9278d56a42304324b006f78133df0152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=244418560.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "alexnet = models.alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "vgg16.classifier[6] = nn.Linear(4096,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16()\n",
    "model.classifier = nn.Sequential(nn.Linear(25088, 4096),\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.Dropout(0.2),\n",
    "                                         nn.Linear(4096, 1024),\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.Dropout(0.2),\n",
    "                                         nn.Linear(1024,512),\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.Dropout(0.2),\n",
    "                                         nn.Linear(512, 7))\n",
    "model_dir = \"./\"\n",
    "model_path = os.path.join(model_dir, 'modelVGG.pth')\n",
    "with open(model_path, 'rb') as f:\n",
    "    model.load_state_dict(torch.load(f))\n",
    "#model =model.load_state_dict(torch.load())\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#model = vgg16\n",
    "model.to(device)\n",
    "test_loss = 0\n",
    "accuracy = 0\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for inputs, labels in testloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        logps = model.forward(inputs)\n",
    "        m = nn.LogSoftmax(dim=1)\n",
    "        batch_loss = loss_fn(m(logps), labels)\n",
    "\n",
    "        test_loss += batch_loss.item()\n",
    "        #accuracy = 0\n",
    "        # Calculate accuracy\n",
    "        ps = torch.exp(logps)\n",
    "        top_p, top_class = ps.topk(1, dim=1)\n",
    "        equals = top_class == labels.view(*top_class.shape)\n",
    "        accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "        print(f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
    "                f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n",
    "print(f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
    "\tf\"Test accuracy: {accuracy/len(testloader):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(entry_point=\"train-PreTrained.py\",\n",
    "                    source_dir=\"./\",\n",
    "                    role=role,\n",
    "                    framework_version='1.0.0',\n",
    "                    py_version='py3',\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type='ml.p2.xlarge',\n",
    "                    output_path='s3://{}/{}/output'.format(sagemaker_session.default_bucket(), prefix),\n",
    "                    hyperparameters={\n",
    "                        'epochs': 70,\n",
    "                        'learning_rate': 0.0008,\n",
    "                        'model_name':\"alexnet\"\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-12 09:47:37 Starting - Starting the training job...\n",
      "2020-12-12 09:48:00 Starting - Launching requested ML instancesProfilerReport-1607766423: InProgress\n",
      "......\n",
      "2020-12-12 09:49:01 Starting - Preparing the instances for training.........\n",
      "2020-12-12 09:50:23 Downloading - Downloading input data.........\n",
      "2020-12-12 09:52:03 Training - Downloading the training image..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-12-12 09:52:15,554 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-12-12 09:52:15,580 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-12-12 09:52:15,581 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\n",
      "2020-12-12 09:52:24 Training - Training image download completed. Training in progress.\u001b[34m2020-12-12 09:52:32,394 sagemaker-containers INFO     Module train-PreTrained does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-12-12 09:52:32,578 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-12-12 09:52:32,578 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-12-12 09:52:32,579 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install -U . -r requirements.txt\u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mCollecting sagemaker-containers (from -r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/f3/4d/ee2ef5a6cccdcf39aa1b3c8f978a462f0c32faddab807a8ba3506b898262/sagemaker_containers-2.8.6.post2.tar.gz (51kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from sagemaker-containers->-r requirements.txt (line 1)) (1.16.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: boto3 in /usr/local/lib/python3.6/dist-packages (from sagemaker-containers->-r requirements.txt (line 1)) (1.9.158)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from sagemaker-containers->-r requirements.txt (line 1)) (1.12.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: pip in /usr/local/lib/python3.6/dist-packages (from sagemaker-containers->-r requirements.txt (line 1)) (18.1)\u001b[0m\n",
      "\u001b[34mCollecting flask==1.1.1 (from sagemaker-containers->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/9b/93/628509b8d5dc749656a9641f4caf13540e2cdec85276964ff8f43bbb1d3b/Flask-1.1.1-py2.py3-none-any.whl (94kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: gunicorn in /usr/local/lib/python3.6/dist-packages (from sagemaker-containers->-r requirements.txt (line 1)) (19.9.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: typing in /usr/local/lib/python3.6/dist-packages (from sagemaker-containers->-r requirements.txt (line 1)) (3.6.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from sagemaker-containers->-r requirements.txt (line 1)) (1.3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: gevent in /usr/local/lib/python3.6/dist-packages (from sagemaker-containers->-r requirements.txt (line 1)) (1.4.0)\u001b[0m\n",
      "\u001b[34mCollecting inotify_simple==1.2.1 (from sagemaker-containers->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/7b/2d/c7450cc2c6ec9be3a6f35d7d22f6866f156a32f4ea97e75b13b27ad300fd/inotify_simple-1.2.1.tar.gz\u001b[0m\n",
      "\u001b[34mCollecting werkzeug>=0.15.5 (from sagemaker-containers->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/cc/94/5f7079a0e00bd6863ef8f1da638721e9da21e5bacee597595b318f71d62e/Werkzeug-1.0.1-py2.py3-none-any.whl (298kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: paramiko>=2.4.2 in /usr/local/lib/python3.6/dist-packages (from sagemaker-containers->-r requirements.txt (line 1)) (2.4.2)\u001b[0m\n",
      "\u001b[34mCollecting psutil>=5.6.7 (from sagemaker-containers->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/33/e0/82d459af36bda999f82c7ea86c67610591cf5556168f48fd6509e5fa154d/psutil-5.7.3.tar.gz (465kB)\u001b[0m\n",
      "\u001b[34mCollecting protobuf>=3.1 (from sagemaker-containers->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/fe/fd/247ef25f5ec5f9acecfbc98ca3c6aaf66716cf52509aca9a93583d410493/protobuf-3.14.0-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: scipy>=1.2.2 in /usr/local/lib/python3.6/dist-packages (from sagemaker-containers->-r requirements.txt (line 1)) (1.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->sagemaker-containers->-r requirements.txt (line 1)) (0.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->sagemaker-containers->-r requirements.txt (line 1)) (0.9.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: botocore<1.13.0,>=1.12.158 in /usr/local/lib/python3.6/dist-packages (from boto3->sagemaker-containers->-r requirements.txt (line 1)) (1.12.158)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask==1.1.1->sagemaker-containers->-r requirements.txt (line 1)) (7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from flask==1.1.1->sagemaker-containers->-r requirements.txt (line 1)) (2.10.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask==1.1.1->sagemaker-containers->-r requirements.txt (line 1)) (1.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: greenlet>=0.4.14; platform_python_implementation == \"CPython\" in /usr/local/lib/python3.6/dist-packages (from gevent->sagemaker-containers->-r requirements.txt (line 1)) (0.4.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: pynacl>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from paramiko>=2.4.2->sagemaker-containers->-r requirements.txt (line 1)) (1.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: cryptography>=1.5 in /usr/local/lib/python3.6/dist-packages (from paramiko>=2.4.2->sagemaker-containers->-r requirements.txt (line 1)) (2.6.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: bcrypt>=3.1.3 in /usr/local/lib/python3.6/dist-packages (from paramiko>=2.4.2->sagemaker-containers->-r requirements.txt (line 1)) (3.1.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from paramiko>=2.4.2->sagemaker-containers->-r requirements.txt (line 1)) (0.4.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.158->boto3->sagemaker-containers->-r requirements.txt (line 1)) (0.14)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.158->boto3->sagemaker-containers->-r requirements.txt (line 1)) (2.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: urllib3<1.26,>=1.20; python_version >= \"3.4\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.158->boto3->sagemaker-containers->-r requirements.txt (line 1)) (1.25.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->flask==1.1.1->sagemaker-containers->-r requirements.txt (line 1)) (1.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: cffi>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from pynacl>=1.0.1->paramiko>=2.4.2->sagemaker-containers->-r requirements.txt (line 1)) (1.12.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: asn1crypto>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from cryptography>=1.5->paramiko>=2.4.2->sagemaker-containers->-r requirements.txt (line 1)) (0.24.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.4.1->pynacl>=1.0.1->paramiko>=2.4.2->sagemaker-containers->-r requirements.txt (line 1)) (2.19)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: sagemaker-containers, train-PreTrained, inotify-simple, psutil\n",
      "  Running setup.py bdist_wheel for sagemaker-containers: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for sagemaker-containers: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/7e/8f/2d/8d3d759b6ec3a3be6f838856cc3c734412868a7ea16c57043f\n",
      "  Running setup.py bdist_wheel for train-PreTrained: started\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m  Running setup.py bdist_wheel for train-PreTrained: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-x0g6kxa9/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for inotify-simple: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for inotify-simple: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/28/77/f9/52cc89b27110b3fe0df40290275bd1151db9d0c7b15733cc3b\n",
      "  Running setup.py bdist_wheel for psutil: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for psutil: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/42/32/da/8b12fd6b138c733efd03cfde6c6c8191a32842f9e82aa45fbf\u001b[0m\n",
      "\u001b[34mSuccessfully built sagemaker-containers train-PreTrained inotify-simple psutil\u001b[0m\n",
      "\u001b[34mInstalling collected packages: werkzeug, flask, inotify-simple, psutil, protobuf, sagemaker-containers, train-PreTrained\n",
      "  Found existing installation: Werkzeug 0.15.4\u001b[0m\n",
      "\u001b[34m    Uninstalling Werkzeug-0.15.4:\n",
      "      Successfully uninstalled Werkzeug-0.15.4\n",
      "  Found existing installation: Flask 1.0.3\n",
      "    Uninstalling Flask-1.0.3:\n",
      "      Successfully uninstalled Flask-1.0.3\n",
      "  Found existing installation: inotify-simple 1.1.8\n",
      "    Uninstalling inotify-simple-1.1.8:\n",
      "      Successfully uninstalled inotify-simple-1.1.8\n",
      "  Found existing installation: psutil 5.4.8\n",
      "    Uninstalling psutil-5.4.8:\n",
      "      Successfully uninstalled psutil-5.4.8\n",
      "  Found existing installation: sagemaker-containers 2.4.10.post0\n",
      "    Uninstalling sagemaker-containers-2.4.10.post0:\n",
      "      Successfully uninstalled sagemaker-containers-2.4.10.post0\u001b[0m\n",
      "\u001b[34mSuccessfully installed flask-1.1.1 inotify-simple-1.2.1 protobuf-3.14.0 psutil-5.7.3 sagemaker-containers-2.8.6.post2 train-PreTrained-1.0.0 werkzeug-1.0.1\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 20.3.1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-12-12 09:53:55,663 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"model_name\": \"alexnet\",\n",
      "        \"epochs\": 70,\n",
      "        \"learning_rate\": 0.0008\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-pytorch-2020-12-12-09-47-03-727\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-769207522942/sagemaker-pytorch-2020-12-12-09-47-03-727/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train-PreTrained\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train-PreTrained.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":70,\"learning_rate\":0.0008,\"model_name\":\"alexnet\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train-PreTrained.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train-PreTrained\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-769207522942/sagemaker-pytorch-2020-12-12-09-47-03-727/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":70,\"learning_rate\":0.0008,\"model_name\":\"alexnet\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-pytorch-2020-12-12-09-47-03-727\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-769207522942/sagemaker-pytorch-2020-12-12-09-47-03-727/source/sourcedir.tar.gz\",\"module_name\":\"train-PreTrained\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train-PreTrained.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"70\",\"--learning_rate\",\"0.0008\",\"--model_name\",\"alexnet\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_NAME=alexnet\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=70\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.0008\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m train-PreTrained --epochs 70 --learning_rate 0.0008 --model_name alexnet\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cuda.\u001b[0m\n",
      "\u001b[34mGet train and valid data loader.\u001b[0m\n",
      "\u001b[34mEpoch: 1, NLLLoss: 1.8242998957633971\u001b[0m\n",
      "\u001b[34mEpoch 2/70.. Train loss: 1.824.. Valid loss: 1.690.. Validation accuracy: 0.283\u001b[0m\n",
      "\u001b[34mEpoch: 2, NLLLoss: 1.6729237258434295\u001b[0m\n",
      "\u001b[34mEpoch 3/70.. Train loss: 1.673.. Valid loss: 1.633.. Validation accuracy: 0.299\u001b[0m\n",
      "\u001b[34mEpoch: 3, NLLLoss: 1.6578404784202576\u001b[0m\n",
      "\u001b[34mEpoch 4/70.. Train loss: 1.658.. Valid loss: 1.553.. Validation accuracy: 0.310\u001b[0m\n",
      "\u001b[34mEpoch: 4, NLLLoss: 1.6164292514324188\u001b[0m\n",
      "\u001b[34mEpoch 5/70.. Train loss: 1.616.. Valid loss: 1.498.. Validation accuracy: 0.335\u001b[0m\n",
      "\u001b[34mEpoch: 5, NLLLoss: 1.6176215708255768\u001b[0m\n",
      "\u001b[34mEpoch 6/70.. Train loss: 1.618.. Valid loss: 1.629.. Validation accuracy: 0.310\u001b[0m\n",
      "\u001b[34mEpoch: 6, NLLLoss: 1.6186269879341126\u001b[0m\n",
      "\u001b[34mEpoch 7/70.. Train loss: 1.619.. Valid loss: 1.489.. Validation accuracy: 0.321\u001b[0m\n",
      "\u001b[34mEpoch: 7, NLLLoss: 1.5962667763233185\u001b[0m\n",
      "\u001b[34mEpoch 8/70.. Train loss: 1.596.. Valid loss: 1.422.. Validation accuracy: 0.424\u001b[0m\n",
      "\u001b[34mEpoch: 8, NLLLoss: 1.5747427821159363\u001b[0m\n",
      "\u001b[34mEpoch 9/70.. Train loss: 1.575.. Valid loss: 1.436.. Validation accuracy: 0.346\u001b[0m\n",
      "\u001b[34mEpoch: 9, NLLLoss: 1.5889233112335206\u001b[0m\n",
      "\u001b[34mEpoch 10/70.. Train loss: 1.589.. Valid loss: 1.450.. Validation accuracy: 0.414\u001b[0m\n",
      "\u001b[34mEpoch: 10, NLLLoss: 1.5439424753189086\u001b[0m\n",
      "\u001b[34mEpoch 11/70.. Train loss: 1.544.. Valid loss: 1.354.. Validation accuracy: 0.453\u001b[0m\n",
      "\u001b[34mEpoch: 11, NLLLoss: 1.5364103674888612\u001b[0m\n",
      "\u001b[34mEpoch 12/70.. Train loss: 1.536.. Valid loss: 1.431.. Validation accuracy: 0.519\u001b[0m\n",
      "\u001b[34mEpoch: 12, NLLLoss: 1.554297399520874\u001b[0m\n",
      "\u001b[34mEpoch 13/70.. Train loss: 1.554.. Valid loss: 1.300.. Validation accuracy: 0.490\u001b[0m\n",
      "\u001b[34mEpoch: 13, NLLLoss: 1.5227966248989104\u001b[0m\n",
      "\u001b[34mEpoch 14/70.. Train loss: 1.523.. Valid loss: 1.335.. Validation accuracy: 0.495\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mEpoch: 14, NLLLoss: 1.498760163784027\u001b[0m\n",
      "\u001b[34mEpoch 15/70.. Train loss: 1.499.. Valid loss: 1.383.. Validation accuracy: 0.479\u001b[0m\n",
      "\u001b[34mEpoch: 15, NLLLoss: 1.500464391708374\u001b[0m\n",
      "\u001b[34mEpoch 16/70.. Train loss: 1.500.. Valid loss: 1.246.. Validation accuracy: 0.524\u001b[0m\n",
      "\u001b[34mEpoch: 16, NLLLoss: 1.5007070362567902\u001b[0m\n",
      "\u001b[34mEpoch 17/70.. Train loss: 1.501.. Valid loss: 1.318.. Validation accuracy: 0.527\u001b[0m\n",
      "\u001b[34mEpoch: 17, NLLLoss: 1.4883985340595245\u001b[0m\n",
      "\u001b[34mEpoch 18/70.. Train loss: 1.488.. Valid loss: 1.280.. Validation accuracy: 0.490\u001b[0m\n",
      "\u001b[34mEpoch: 18, NLLLoss: 1.4695859909057618\u001b[0m\n",
      "\u001b[34mEpoch 19/70.. Train loss: 1.470.. Valid loss: 1.225.. Validation accuracy: 0.516\u001b[0m\n",
      "\u001b[34mEpoch: 19, NLLLoss: 1.4495676100254058\u001b[0m\n",
      "\u001b[34mEpoch 20/70.. Train loss: 1.450.. Valid loss: 1.262.. Validation accuracy: 0.512\u001b[0m\n",
      "\u001b[34mEpoch: 20, NLLLoss: 1.4511398911476134\u001b[0m\n",
      "\u001b[34mEpoch 21/70.. Train loss: 1.451.. Valid loss: 1.224.. Validation accuracy: 0.549\u001b[0m\n",
      "\u001b[34mEpoch: 21, NLLLoss: 1.425150465965271\u001b[0m\n",
      "\u001b[34mEpoch 22/70.. Train loss: 1.425.. Valid loss: 1.231.. Validation accuracy: 0.512\u001b[0m\n",
      "\u001b[34mEpoch: 22, NLLLoss: 1.464549458026886\u001b[0m\n",
      "\u001b[34mEpoch 23/70.. Train loss: 1.465.. Valid loss: 1.254.. Validation accuracy: 0.537\u001b[0m\n",
      "\u001b[34mEpoch: 23, NLLLoss: 1.4537885546684266\u001b[0m\n",
      "\u001b[34mEpoch 24/70.. Train loss: 1.454.. Valid loss: 1.271.. Validation accuracy: 0.537\u001b[0m\n",
      "\u001b[34mEpoch: 24, NLLLoss: 1.427037423849106\u001b[0m\n",
      "\u001b[34mEpoch 25/70.. Train loss: 1.427.. Valid loss: 1.220.. Validation accuracy: 0.549\u001b[0m\n",
      "\u001b[34mEpoch: 25, NLLLoss: 1.4309998810291291\u001b[0m\n",
      "\u001b[34mEpoch 26/70.. Train loss: 1.431.. Valid loss: 1.254.. Validation accuracy: 0.549\u001b[0m\n",
      "\u001b[34mEpoch: 26, NLLLoss: 1.4314132750034332\u001b[0m\n",
      "\u001b[34mEpoch 27/70.. Train loss: 1.431.. Valid loss: 1.268.. Validation accuracy: 0.553\u001b[0m\n",
      "\u001b[34mEpoch: 27, NLLLoss: 1.4380509316921235\u001b[0m\n",
      "\u001b[34mEpoch 28/70.. Train loss: 1.438.. Valid loss: 1.310.. Validation accuracy: 0.507\u001b[0m\n",
      "\u001b[34mEpoch: 28, NLLLoss: 1.4219686329364776\u001b[0m\n",
      "\u001b[34mEpoch 29/70.. Train loss: 1.422.. Valid loss: 1.203.. Validation accuracy: 0.541\u001b[0m\n",
      "\u001b[34mEpoch: 29, NLLLoss: 1.4316133856773376\u001b[0m\n",
      "\u001b[34mEpoch 30/70.. Train loss: 1.432.. Valid loss: 1.199.. Validation accuracy: 0.556\u001b[0m\n",
      "\u001b[34mEpoch: 30, NLLLoss: 1.3862544059753419\u001b[0m\n",
      "\u001b[34mEpoch 31/70.. Train loss: 1.386.. Valid loss: 1.154.. Validation accuracy: 0.588\u001b[0m\n",
      "\u001b[34mEpoch: 31, NLLLoss: 1.346248948574066\u001b[0m\n",
      "\u001b[34mEpoch 32/70.. Train loss: 1.346.. Valid loss: 1.179.. Validation accuracy: 0.555\u001b[0m\n",
      "\u001b[34mEpoch: 32, NLLLoss: 1.371890652179718\u001b[0m\n",
      "\u001b[34mEpoch 33/70.. Train loss: 1.372.. Valid loss: 1.242.. Validation accuracy: 0.536\u001b[0m\n",
      "\u001b[34mEpoch: 33, NLLLoss: 1.3716149806976319\u001b[0m\n",
      "\u001b[34mEpoch 34/70.. Train loss: 1.372.. Valid loss: 1.174.. Validation accuracy: 0.550\u001b[0m\n",
      "\u001b[34mEpoch: 34, NLLLoss: 1.3962359428405762\u001b[0m\n",
      "\u001b[34mEpoch 35/70.. Train loss: 1.396.. Valid loss: 1.195.. Validation accuracy: 0.548\u001b[0m\n",
      "\u001b[34mEpoch: 35, NLLLoss: 1.3944140732288361\u001b[0m\n",
      "\u001b[34mEpoch 36/70.. Train loss: 1.394.. Valid loss: 1.135.. Validation accuracy: 0.594\u001b[0m\n",
      "\u001b[34mEpoch: 36, NLLLoss: 1.322671264410019\u001b[0m\n",
      "\u001b[34mEpoch 37/70.. Train loss: 1.323.. Valid loss: 1.221.. Validation accuracy: 0.560\u001b[0m\n",
      "\u001b[34mEpoch: 37, NLLLoss: 1.363169676065445\u001b[0m\n",
      "\u001b[34mEpoch 38/70.. Train loss: 1.363.. Valid loss: 1.156.. Validation accuracy: 0.578\u001b[0m\n",
      "\u001b[34mEpoch: 38, NLLLoss: 1.3670533537864684\u001b[0m\n",
      "\u001b[34mEpoch 39/70.. Train loss: 1.367.. Valid loss: 1.256.. Validation accuracy: 0.532\u001b[0m\n",
      "\u001b[34mEpoch: 39, NLLLoss: 1.4009125292301179\u001b[0m\n",
      "\u001b[34mEpoch 40/70.. Train loss: 1.401.. Valid loss: 1.161.. Validation accuracy: 0.560\u001b[0m\n",
      "\u001b[34mEpoch: 40, NLLLoss: 1.3258517682552338\u001b[0m\n",
      "\u001b[34mEpoch 41/70.. Train loss: 1.326.. Valid loss: 1.144.. Validation accuracy: 0.589\u001b[0m\n",
      "\u001b[34mEpoch: 41, NLLLoss: 1.342771977186203\u001b[0m\n",
      "\u001b[34mEpoch 42/70.. Train loss: 1.343.. Valid loss: 1.239.. Validation accuracy: 0.542\u001b[0m\n",
      "\u001b[34mEpoch: 42, NLLLoss: 1.3524689614772796\u001b[0m\n",
      "\u001b[34mEpoch 43/70.. Train loss: 1.352.. Valid loss: 1.123.. Validation accuracy: 0.581\u001b[0m\n",
      "\u001b[34mEpoch: 43, NLLLoss: 1.3471360146999358\u001b[0m\n",
      "\u001b[34mEpoch 44/70.. Train loss: 1.347.. Valid loss: 1.182.. Validation accuracy: 0.576\u001b[0m\n",
      "\u001b[34mEpoch: 44, NLLLoss: 1.3242457032203674\u001b[0m\n",
      "\u001b[34mEpoch 45/70.. Train loss: 1.324.. Valid loss: 1.165.. Validation accuracy: 0.548\u001b[0m\n",
      "\u001b[34mEpoch: 45, NLLLoss: 1.303893405199051\u001b[0m\n",
      "\u001b[34mEpoch 46/70.. Train loss: 1.304.. Valid loss: 1.145.. Validation accuracy: 0.550\u001b[0m\n",
      "\u001b[34mEpoch: 46, NLLLoss: 1.2859830617904664\u001b[0m\n",
      "\u001b[34mEpoch 47/70.. Train loss: 1.286.. Valid loss: 1.182.. Validation accuracy: 0.574\u001b[0m\n",
      "\u001b[34mEpoch: 47, NLLLoss: 1.3494730353355409\u001b[0m\n",
      "\u001b[34mEpoch 48/70.. Train loss: 1.349.. Valid loss: 1.172.. Validation accuracy: 0.537\u001b[0m\n",
      "\u001b[34mEpoch: 48, NLLLoss: 1.3092677533626556\u001b[0m\n",
      "\u001b[34mEpoch 49/70.. Train loss: 1.309.. Valid loss: 1.147.. Validation accuracy: 0.585\u001b[0m\n",
      "\u001b[34mEpoch: 49, NLLLoss: 1.3131919860839845\u001b[0m\n",
      "\u001b[34mEpoch 50/70.. Train loss: 1.313.. Valid loss: 1.155.. Validation accuracy: 0.609\u001b[0m\n",
      "\u001b[34mEpoch: 50, NLLLoss: 1.314095801115036\u001b[0m\n",
      "\u001b[34mEpoch 51/70.. Train loss: 1.314.. Valid loss: 1.084.. Validation accuracy: 0.608\u001b[0m\n",
      "\u001b[34mEpoch: 51, NLLLoss: 1.305889254808426\u001b[0m\n",
      "\u001b[34mEpoch 52/70.. Train loss: 1.306.. Valid loss: 1.119.. Validation accuracy: 0.582\u001b[0m\n",
      "\u001b[34mEpoch: 52, NLLLoss: 1.2891346156597137\u001b[0m\n",
      "\u001b[34mEpoch 53/70.. Train loss: 1.289.. Valid loss: 1.143.. Validation accuracy: 0.588\u001b[0m\n",
      "\u001b[34mEpoch: 53, NLLLoss: 1.3255964457988738\u001b[0m\n",
      "\u001b[34mEpoch 54/70.. Train loss: 1.326.. Valid loss: 1.121.. Validation accuracy: 0.602\u001b[0m\n",
      "\u001b[34mEpoch: 54, NLLLoss: 1.2666154623031616\u001b[0m\n",
      "\u001b[34mEpoch 55/70.. Train loss: 1.267.. Valid loss: 1.117.. Validation accuracy: 0.609\u001b[0m\n",
      "\u001b[34mEpoch: 55, NLLLoss: 1.2643017053604126\u001b[0m\n",
      "\u001b[34mEpoch 56/70.. Train loss: 1.264.. Valid loss: 1.159.. Validation accuracy: 0.554\u001b[0m\n",
      "\u001b[34mEpoch: 56, NLLLoss: 1.2743840515613556\u001b[0m\n",
      "\u001b[34mEpoch 57/70.. Train loss: 1.274.. Valid loss: 1.184.. Validation accuracy: 0.572\u001b[0m\n",
      "\u001b[34mEpoch: 57, NLLLoss: 1.2767883718013764\u001b[0m\n",
      "\u001b[34mEpoch 58/70.. Train loss: 1.277.. Valid loss: 1.127.. Validation accuracy: 0.576\u001b[0m\n",
      "\u001b[34mEpoch: 58, NLLLoss: 1.2755516111850738\u001b[0m\n",
      "\u001b[34mEpoch 59/70.. Train loss: 1.276.. Valid loss: 1.176.. Validation accuracy: 0.555\u001b[0m\n",
      "\u001b[34mEpoch: 59, NLLLoss: 1.2867828547954558\u001b[0m\n",
      "\u001b[34mEpoch 60/70.. Train loss: 1.287.. Valid loss: 1.141.. Validation accuracy: 0.588\u001b[0m\n",
      "\u001b[34mEpoch: 60, NLLLoss: 1.271361917257309\u001b[0m\n",
      "\u001b[34mEpoch 61/70.. Train loss: 1.271.. Valid loss: 1.191.. Validation accuracy: 0.584\u001b[0m\n",
      "\u001b[34mEpoch: 61, NLLLoss: 1.2920564889907837\u001b[0m\n",
      "\u001b[34mEpoch 62/70.. Train loss: 1.292.. Valid loss: 1.174.. Validation accuracy: 0.537\u001b[0m\n",
      "\u001b[34mEpoch: 62, NLLLoss: 1.2683957099914551\u001b[0m\n",
      "\u001b[34mEpoch 63/70.. Train loss: 1.268.. Valid loss: 1.123.. Validation accuracy: 0.558\u001b[0m\n",
      "\u001b[34mEpoch: 63, NLLLoss: 1.2349920511245727\u001b[0m\n",
      "\u001b[34mEpoch 64/70.. Train loss: 1.235.. Valid loss: 1.114.. Validation accuracy: 0.623\u001b[0m\n",
      "\u001b[34mEpoch: 64, NLLLoss: 1.2405994415283204\u001b[0m\n",
      "\u001b[34mEpoch 65/70.. Train loss: 1.241.. Valid loss: 1.139.. Validation accuracy: 0.603\u001b[0m\n",
      "\u001b[34mEpoch: 65, NLLLoss: 1.220258504152298\u001b[0m\n",
      "\u001b[34mEpoch 66/70.. Train loss: 1.220.. Valid loss: 1.183.. Validation accuracy: 0.561\u001b[0m\n",
      "\u001b[34mEpoch: 66, NLLLoss: 1.2706393361091615\u001b[0m\n",
      "\u001b[34mEpoch 67/70.. Train loss: 1.271.. Valid loss: 1.182.. Validation accuracy: 0.573\u001b[0m\n",
      "\u001b[34mEpoch: 67, NLLLoss: 1.292889791727066\u001b[0m\n",
      "\u001b[34mEpoch 68/70.. Train loss: 1.293.. Valid loss: 1.110.. Validation accuracy: 0.612\u001b[0m\n",
      "\u001b[34mEpoch: 68, NLLLoss: 1.2430004537105561\u001b[0m\n",
      "\u001b[34mEpoch 69/70.. Train loss: 1.243.. Valid loss: 1.067.. Validation accuracy: 0.628\u001b[0m\n",
      "\u001b[34mEpoch: 69, NLLLoss: 1.2423635959625243\u001b[0m\n",
      "\u001b[34mEpoch 70/70.. Train loss: 1.242.. Valid loss: 1.029.. Validation accuracy: 0.642\u001b[0m\n",
      "\u001b[34mEpoch: 70, NLLLoss: 1.2295817971229552\u001b[0m\n",
      "\u001b[34mEpoch 71/70.. Train loss: 1.230.. Valid loss: 1.076.. Validation accuracy: 0.619\u001b[0m\n",
      "\u001b[34m2020-12-12 10:07:15,978 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-12-12 10:08:16 Uploading - Uploading generated training model\n",
      "2020-12-12 10:08:36 Completed - Training job completed\n",
      "ProfilerReport-1607766423: IssuesFound\n",
      "Training seconds: 1082\n",
      "Billable seconds: 1082\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({'training':output_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion-detection/output/sagemaker-pytorch-2020-12-10-05-32-54-649/output/model.tar.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sagemaker-pytorch-2020-12-10-05-32-54-649##VGG\n",
    "#sagemaker-pytorch-2020-12-12-09-47-03-727##Alex\n",
    "#sagemaker-pytorch-2020-12-05-13-09-13-645 --27\n",
    "#sagemaker-pytorch-2020-12-10-05-32-54-649\n",
    "import os\n",
    "training_job_name='sagemaker-pytorch-2020-12-10-05-32-54-649'\n",
    "\n",
    "# where the model is saved, by default\n",
    "model_key = os.path.join(prefix, \"output\",training_job_name, 'output/model.tar.gz')\n",
    "print(model_key)\n",
    "\n",
    "#s3://sagemaker-us-east-2-769207522942/emotion-detection/output/sagemaker-pytorch-2020-12-05-09-07-48-004/output/model.tar.gz \n",
    "# download and unzip model\n",
    "boto3.resource('s3').Bucket(bucket).download_file(model_key, 'model.tar.gz')\n",
    "\n",
    "# unzipping as model_algo-1\n",
    "os.system('tar -zxvf model.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 654676\r\n",
      "-rw-rw-r-- 1 ec2-user ec2-user        96 Dec  4 06:17 category.json\r\n",
      "drwxrwxr-x 2 ec2-user ec2-user      4096 Dec  3 12:14 data\r\n",
      "-rw-rw-r-- 1 ec2-user ec2-user    359900 Dec 12 11:47 FacialExpression.ipynb\r\n",
      "drwxrwxr-x 2 ec2-user ec2-user    638976 Dec  3 12:14 images\r\n",
      "-rw-rw-r-- 1 ec2-user ec2-user     11357 Dec  3 12:14 LICENSE\r\n",
      "-rw-r--r-- 1 ec2-user ec2-user 179787972 Dec 12 10:07 modelalexnet.pth\r\n",
      "-rw-rw-r-- 1 ec2-user ec2-user      3212 Dec 12 10:44 model.py\r\n",
      "-rw-r--r-- 1 ec2-user ec2-user 488817546 Dec 10 06:23 modelVGG.pth\r\n",
      "-rw-rw-r-- 1 ec2-user ec2-user      2762 Dec  4 16:40 predict.py\r\n",
      "drwxrwxr-x 2 ec2-user ec2-user      4096 Dec 11 08:19 __pycache__\r\n",
      "drwxrwxr-x 2 ec2-user ec2-user      4096 Dec  3 12:14 python\r\n",
      "drwxrwxr-x 2 ec2-user ec2-user      4096 Dec  3 12:14 R\r\n",
      "-rw-rw-r-- 1 ec2-user ec2-user       963 Dec  3 12:14 README.md\r\n",
      "-rw-rw-r-- 1 ec2-user ec2-user        20 Dec  5 12:33 requirements.txt\r\n",
      "drwxrwxr-x 6 ec2-user ec2-user    618496 Dec  4 09:58 selectedImages\r\n",
      "-rw-rw-r-- 1 ec2-user ec2-user     75014 Dec  4 06:12 selectedImages.csv\r\n",
      "drwxrwxr-x 2 ec2-user ec2-user     12288 Dec  3 12:14 test\r\n",
      "-rw-rw-r-- 1 ec2-user ec2-user      8413 Dec 12 09:46 train-PreTrained.py\r\n",
      "-rw-rw-r-- 1 ec2-user ec2-user      7876 Dec 12 10:43 train.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.386.. Test accuracy: 0.502\n"
     ]
    }
   ],
   "source": [
    "model = models.alexnet()\n",
    "model.classifier = nn.Sequential(nn.Linear(9216, 4096),\n",
    "                                             nn.ReLU(),\n",
    "                                             nn.Dropout(0.2),\n",
    "                                             nn.Linear(4096, 1024),\n",
    "                                             nn.ReLU(),\n",
    "                                             nn.Dropout(0.2),\n",
    "                                             nn.Linear(1024,512),\n",
    "                                             nn.ReLU(),\n",
    "                                             nn.Dropout(0.2),\n",
    "                                             nn.Linear(512, 7))\n",
    "model_dir = \"./\"\n",
    "model_path = os.path.join(model_dir, 'modelalexnet.pth')\n",
    "with open(model_path, 'rb') as f:\n",
    "    model.load_state_dict(torch.load(f))\n",
    "#model =model.load_state_dict(torch.load())\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#model = vgg16\n",
    "model.to(device)\n",
    "test_loss = 0\n",
    "accuracy = 0\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "model.to(device)\n",
    "test_loss = 0\n",
    "accuracy = 0\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for inputs, labels in testloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        logps = model.forward(inputs)\n",
    "        y_true.append(labels.item())\n",
    "        m = nn.LogSoftmax(dim=1)\n",
    "        batch_loss = loss_fn(m(logps), labels)\n",
    "\n",
    "        test_loss += batch_loss.item()\n",
    "        #accuracy = 0\n",
    "        # Calculate accuracy\n",
    "        ps = torch.exp(logps)\n",
    "        top_p, top_class = ps.topk(1, dim=1)\n",
    "        y_pred.append(top_class.item())\n",
    "        equals = top_class == labels.view(*top_class.shape)\n",
    "        accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "\n",
    "print(f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
    "\tf\"Test accuracy: {accuracy/len(testloader):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.46      0.31      0.37        52\n",
      "     disgust       0.57      0.74      0.65        43\n",
      "        fear       0.00      0.00      0.00         6\n",
      "   happiness       0.58      0.63      0.60        99\n",
      "     neutral       0.40      0.53      0.45        91\n",
      "     sadness       0.44      0.27      0.33        52\n",
      "    surprise       0.55      0.51      0.53        83\n",
      "\n",
      "    accuracy                           0.50       426\n",
      "   macro avg       0.43      0.43      0.42       426\n",
      "weighted avg       0.50      0.50      0.49       426\n",
      "\n",
      "Confusion Matrix\n",
      "[[16  2  0 12 11  4  7]\n",
      " [ 2 32  0  2  2  5  0]\n",
      " [ 0  3  0  0  2  1  0]\n",
      " [ 6  3  0 62 23  2  3]\n",
      " [ 4  1  0 14 48  3 21]\n",
      " [ 2 14  0  8 11 14  3]\n",
      " [ 5  1  0  8 24  3 42]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#class_labels = {v: k for k, v in class_labels.items()}\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "target_names = (test_data.class_to_idx).keys()\n",
    "print('Classification Report')\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "#y = np.argmax(y_pred, axis=1)\n",
    "cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print('Confusion Matrix')\n",
    "print(cnf_matrix)\n",
    "plt.imshow(cnf_matrix, interpolation='nearest')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(target_names))\n",
    "_ = plt.xticks(tick_marks, target_names, rotation=90)\n",
    "_ = plt.yticks(tick_marks, target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "def process_image(image):\n",
    "    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n",
    "        returns an Numpy array\n",
    "    '''\n",
    "    image_transforms = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                             std=[0.229, 0.224, 0.225])])\n",
    "    \n",
    "    return image_transforms(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image, model, topk=1):\n",
    "    ''' Predict the class (or classes) of an image using a trained deep learning model.\n",
    "    '''\n",
    "\n",
    "    \n",
    "    tensor_image = image\n",
    "    inputs = tensor_image.unsqueeze(0)\n",
    "    device = 'cpu'\n",
    "    inputs = inputs.float()\n",
    "    inputs.to(device)\n",
    "    \n",
    "    model.to(device)\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        logps = model.forward(inputs)\n",
    "        \n",
    "        ps = torch.exp(logps)\n",
    "        top_p, top_class = ps.topk(topk, dim=1)\n",
    "\n",
    "    return top_class.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import EmotionClassifier\n",
    "model = EmotionClassifier()\n",
    "model_dir = \"./\"\n",
    "model_path = os.path.join(model_dir, 'model.pth')\n",
    "with open(model_path, 'rb') as f:\n",
    "    model.load_state_dict(torch.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key(val,my_dict):\n",
    "    for key, value in my_dict.items():\n",
    "         if val == value:\n",
    "             return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "from IPython.core.display import display, HTML\n",
    "from PIL import Image\n",
    "\n",
    "target_names = (test_data.class_to_idx)\n",
    "\n",
    "def displayImage(class_value,num=5):\n",
    "    targetdir = \"./selectedImages/test/\" + class_value\n",
    "    filelist = glob.glob(targetdir+str(\"/*\"))\n",
    "    random.shuffle(filelist) \n",
    "    data = pd.DataFrame()\n",
    "\n",
    "    ds = []\n",
    "    for file in filelist[0:num]:\n",
    "        ds.append('<img src=\"{}\" title={} alt=\"img\">'.format(file,os.path.basename(file)))\n",
    "\n",
    "    data = pd.DataFrame(ds,columns=['Input Image'])\n",
    "    ds1 = []\n",
    "    for file in filelist[0:num]:\n",
    "        #ds1.append(os.path.basename(file))\n",
    "        im1 = cv2.imread(file)\n",
    "        #im = Image.open(im1)\n",
    "        image = Image.fromarray(im1, \"RGB\")\n",
    "        image1 = process_image(image)\n",
    "\n",
    "        ds1.append(get_key(predict(image1,model),target_names))\n",
    "\n",
    "\n",
    "    # Insert the new column at position 1.\n",
    "    data.insert(1,\"Predicted Class where true class is {}\".format(class_value),ds1,True)\n",
    "\n",
    "    display(HTML(data.to_html(escape=False)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input Image</th>\n",
       "      <th>Predicted Class where true class is anger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td><img src=\"./selectedImages/test/anger/Billy_Crystal_0004.jpg\" title=Billy_Crystal_0004.jpg alt=\"img\"></td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td><img src=\"./selectedImages/test/anger/Serena_Williams_0028.jpg\" title=Serena_Williams_0028.jpg alt=\"img\"></td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td><img src=\"./selectedImages/test/anger/Jennifer_Capriati_0020.jpg\" title=Jennifer_Capriati_0020.jpg alt=\"img\"></td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td><img src=\"./selectedImages/test/anger/Dwarakish_72.jpg\" title=Dwarakish_72.jpg alt=\"img\"></td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td><img src=\"./selectedImages/test/anger/Serena_Williams_0009.jpg\" title=Serena_Williams_0009.jpg alt=\"img\"></td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displayImage(\"anger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input Image</th>\n",
       "      <th>Predicted Class where true class is happiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td><img src=\"./selectedImages/test/happiness/Michel_Therrien_0001.jpg\" title=Michel_Therrien_0001.jpg alt=\"img\"></td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td><img src=\"./selectedImages/test/happiness/Patti_Labelle_0002.jpg\" title=Patti_Labelle_0002.jpg alt=\"img\"></td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td><img src=\"./selectedImages/test/happiness/Michael_Wayne_0001.jpg\" title=Michael_Wayne_0001.jpg alt=\"img\"></td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td><img src=\"./selectedImages/test/happiness/Miroljub_0001.jpg\" title=Miroljub_0001.jpg alt=\"img\"></td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td><img src=\"./selectedImages/test/happiness/Laura_Bush_0012.jpg\" title=Laura_Bush_0012.jpg alt=\"img\"></td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displayImage(\"happiness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input Image</th>\n",
       "      <th>Predicted Class where true class is neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td><img src=\"./selectedImages/test/neutral/Catherine_Ndereba_0001.jpg\" title=Catherine_Ndereba_0001.jpg alt=\"img\"></td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td><img src=\"./selectedImages/test/neutral/Pervez_Musharraf_0001.jpg\" title=Pervez_Musharraf_0001.jpg alt=\"img\"></td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td><img src=\"./selectedImages/test/neutral/Gary_Winnick_0002.jpg\" title=Gary_Winnick_0002.jpg alt=\"img\"></td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td><img src=\"./selectedImages/test/neutral/Winona_Ryder_0005.jpg\" title=Winona_Ryder_0005.jpg alt=\"img\"></td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td><img src=\"./selectedImages/test/neutral/Vicente_Fox_0019.jpg\" title=Vicente_Fox_0019.jpg alt=\"img\"></td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displayImage(\"neutral\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
